{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import re\n",
    "\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import Identity\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Module\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Sigmoid\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision import transforms as Transforms\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import mimetypes\n",
    "import argparse\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"dataset\"\n",
    "IMAGES_PATH = os.path.sep.join([BASE_PATH, \"images\"])\n",
    "ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"annotations\"])\n",
    "\n",
    "BASE_OUTPUT = \"output\"\n",
    "\n",
    "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"detector.pth\"])\n",
    "LE_PATH = os.path.sep.join([BASE_OUTPUT, \"le.pickle\"])\n",
    "PLOTS_PATH = os.path.sep.join([BASE_OUTPUT, \"plots\"])\n",
    "TEST_PATHS = os.path.sep.join([BASE_OUTPUT, \"test_paths.txt\"])\n",
    "ALL_PATHS = os.path.sep.join([\"image_paths.txt\"])\n",
    "PREDICT_PATHS = os.path.sep.join([\"predict_output\", \"bbox.txt\"])\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "INIT_LR = 0.0064\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "LABELS = 1.0\n",
    "BBOX = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
    "\n",
    "# MEAN = [0.485, 0.456, 0.406]\n",
    "# STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# INIT_LR = 1e-4\n",
    "# NUM_EPOCHS = 15\n",
    "# BATCH_SIZE = 16\n",
    "\n",
    "# LABELS = 1.0\n",
    "# BBOX = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorDataset(Dataset):\n",
    "\t# initialize the constructor\n",
    "\tdef __init__(self, tensors, transforms=None):\n",
    "\t\tself.tensors = tensors\n",
    "\t\tself.transforms = transforms\n",
    "\tdef __getitem__(self, index):\n",
    "\t\t# grab the image, label, and its bounding box coordinates\n",
    "\t\timage = self.tensors[0][index]\n",
    "\t\tlabel = self.tensors[1][index]\n",
    "\t\tbbox = self.tensors[2][index]\n",
    "\t\t# transpose the image such that its channel dimension becomes\n",
    "\t\t# the leading one\n",
    "\t\timage = image.permute(2, 0, 1)\n",
    "\t\t# check to see if we have any image transformations to apply\n",
    "\t\t# and if so, apply them\n",
    "\t\tif self.transforms:\n",
    "\t\t\timage = self.transforms(image)\n",
    "\t\t# return a tuple of the images, labels, and bounding\n",
    "\t\t# box coordinates\n",
    "\t\treturn (image, label, bbox)\n",
    "\tdef __len__(self):\n",
    "\t\t# return the size of the dataset\n",
    "\t\treturn self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetector(Module):\n",
    "\tdef __init__(self, baseModel, numClasses):\n",
    "\t\tsuper(ObjectDetector, self).__init__()\n",
    "\t\t# initialize the base model and the number of classes\n",
    "\t\tself.baseModel = baseModel\n",
    "\t\tself.numClasses = numClasses\n",
    "\t\t# build the regressor head for outputting the bounding box\n",
    "\t\t# coordinates\n",
    "\t\tself.regressor = Sequential(\n",
    "\t\t\tLinear(baseModel.fc.in_features, 128),\n",
    "\t\t\tReLU(),\n",
    "\t\t\tLinear(128, 64),\n",
    "\t\t\tReLU(),\n",
    "\t\t\tLinear(64, 32),\n",
    "\t\t\tReLU(),\n",
    "\t\t\tLinear(32, 4),\n",
    "\t\t\tSigmoid()\n",
    "\t\t)\n",
    "\t\t# build the classifier head to predict the class labels\n",
    "\t\tself.classifier = Sequential(\n",
    "\t\t\tLinear(baseModel.fc.in_features, 512),\n",
    "\t\t\tReLU(),\n",
    "\t\t\tDropout(),\n",
    "\t\t\tLinear(512, 512),\n",
    "\t\t\tReLU(),\n",
    "\t\t\tDropout(),\n",
    "\t\t\tLinear(512, self.numClasses)\n",
    "\t\t)\n",
    "\t\t# set the classifier of our base model to produce outputs\n",
    "\t\t# from the last convolution block\n",
    "\t\tself.baseModel.fc = Identity()\n",
    "\tdef forward(self, x):\n",
    "\t\t# pass the inputs through the base model and then obtain\n",
    "\t\t# predictions from two different branches of the network\n",
    "\t\tfeatures = self.baseModel(x)\n",
    "\t\tbboxes = self.regressor(features)\n",
    "\t\tclassLogits = self.classifier(features)\n",
    "\n",
    "\n",
    "\t\t# return the outputs as a tuple\n",
    "\t\treturn (bboxes,classLogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading dataset...\n",
      "[INFO] total training samples: 587...\n",
      "[INFO] total test samples: 147...\n",
      "[INFO] saving testing image paths...\n",
      "[INFO] saving image paths...\n",
      "[INFO] training the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [01:31<44:05, 91.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 1/30\n",
      "Train loss: 0.039700, Train accuracy: 1.0000\n",
      "Val loss: 0.019317, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [03:07<44:04, 94.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 2/30\n",
      "Train loss: 0.029385, Train accuracy: 1.0000\n",
      "Val loss: 0.016003, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [04:45<43:06, 95.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 3/30\n",
      "Train loss: 0.023947, Train accuracy: 1.0000\n",
      "Val loss: 0.013703, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [06:19<41:15, 95.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 4/30\n",
      "Train loss: 0.021727, Train accuracy: 1.0000\n",
      "Val loss: 0.013512, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [07:53<39:25, 94.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 5/30\n",
      "Train loss: 0.019307, Train accuracy: 1.0000\n",
      "Val loss: 0.011654, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [09:25<37:31, 93.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 6/30\n",
      "Train loss: 0.017863, Train accuracy: 1.0000\n",
      "Val loss: 0.013072, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [11:00<36:05, 94.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 7/30\n",
      "Train loss: 0.017304, Train accuracy: 1.0000\n",
      "Val loss: 0.013599, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [12:38<35:01, 95.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 8/30\n",
      "Train loss: 0.016451, Train accuracy: 1.0000\n",
      "Val loss: 0.011849, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [14:23<34:28, 98.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 9/30\n",
      "Train loss: 0.015771, Train accuracy: 1.0000\n",
      "Val loss: 0.012550, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [16:05<33:09, 99.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 10/30\n",
      "Train loss: 0.015499, Train accuracy: 1.0000\n",
      "Val loss: 0.011881, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [17:55<32:31, 102.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 11/30\n",
      "Train loss: 0.014705, Train accuracy: 1.0000\n",
      "Val loss: 0.012208, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [19:54<32:19, 107.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 12/30\n",
      "Train loss: 0.015037, Train accuracy: 1.0000\n",
      "Val loss: 0.012965, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [22:02<32:16, 113.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 13/30\n",
      "Train loss: 0.014580, Train accuracy: 1.0000\n",
      "Val loss: 0.013341, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [24:14<31:49, 119.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 14/30\n",
      "Train loss: 0.014546, Train accuracy: 1.0000\n",
      "Val loss: 0.014347, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [25:39<27:12, 108.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 15/30\n",
      "Train loss: 0.014432, Train accuracy: 1.0000\n",
      "Val loss: 0.012404, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [27:33<25:45, 110.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 16/30\n",
      "Train loss: 0.014079, Train accuracy: 1.0000\n",
      "Val loss: 0.012490, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [29:48<25:31, 117.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 17/30\n",
      "Train loss: 0.013733, Train accuracy: 1.0000\n",
      "Val loss: 0.012417, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [32:07<24:51, 124.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 18/30\n",
      "Train loss: 0.012736, Train accuracy: 1.0000\n",
      "Val loss: 0.012070, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [34:17<23:05, 125.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 19/30\n",
      "Train loss: 0.012805, Train accuracy: 1.0000\n",
      "Val loss: 0.013276, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [36:45<22:06, 132.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 20/30\n",
      "Train loss: 0.012763, Train accuracy: 1.0000\n",
      "Val loss: 0.012635, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [39:05<20:13, 134.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 21/30\n",
      "Train loss: 0.012755, Train accuracy: 1.0000\n",
      "Val loss: 0.012933, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [41:24<18:08, 136.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 22/30\n",
      "Train loss: 0.012414, Train accuracy: 1.0000\n",
      "Val loss: 0.011892, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [43:32<15:35, 133.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 23/30\n",
      "Train loss: 0.012769, Train accuracy: 1.0000\n",
      "Val loss: 0.011862, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [46:08<14:01, 140.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 24/30\n",
      "Train loss: 0.012323, Train accuracy: 1.0000\n",
      "Val loss: 0.012394, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [48:34<11:50, 142.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 25/30\n",
      "Train loss: 0.011933, Train accuracy: 1.0000\n",
      "Val loss: 0.012086, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [51:02<09:34, 143.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 26/30\n",
      "Train loss: 0.012045, Train accuracy: 1.0000\n",
      "Val loss: 0.013696, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [53:02<06:49, 136.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 27/30\n",
      "Train loss: 0.011682, Train accuracy: 1.0000\n",
      "Val loss: 0.013477, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [54:42<04:11, 125.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 28/30\n",
      "Train loss: 0.011668, Train accuracy: 1.0000\n",
      "Val loss: 0.011354, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [56:48<02:05, 125.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 29/30\n",
      "Train loss: 0.011785, Train accuracy: 1.0000\n",
      "Val loss: 0.012523, Val accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [59:07<00:00, 118.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.0 587\n",
      "147.0 147\n",
      "[INFO] EPOCH: 30/30\n",
      "Train loss: 0.011645, Train accuracy: 1.0000\n",
      "Val loss: 0.012019, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 3547.71s\n",
      "[INFO] saving object detector model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving label encoder...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the list of data (images), class labels, target bounding\n",
    "# box coordinates, and image paths\n",
    "print(\"[INFO] loading dataset...\")\n",
    "data = []\n",
    "labels = []\n",
    "bboxes = []\n",
    "imagePaths = []\n",
    "\n",
    "\n",
    "# loop over all CSV files in the annotations directory\n",
    "for csvPath in paths.list_files(ANNOTS_PATH, validExts=(\".csv\")):\n",
    "\t# load the contents of the current CSV annotations file\n",
    "\trows = open(csvPath).read().strip().split(\"\\n\")\n",
    "\t# loop over the rows\n",
    "\tfor row in rows:\n",
    "\t\t# break the row into the filename, bounding box coordinates,\n",
    "\t\t# and class label\n",
    "\t\trow = row.split(\",\")\n",
    "\n",
    "\n",
    "\t\tif len(row) > 8 :\n",
    "\t\t\tlabel = row[10]\n",
    "\t\t\tparts = label.split('[')\n",
    "\t\t\tlabel_value = parts[1].split('\"')[1]\n",
    "\t\t\t\n",
    "\t\t\tfilename = row[3]\n",
    "\t\t\tparts2 = filename.split(\"/\")\n",
    "\t\t\timgFile = \"/\".join(parts2[4:])\n",
    "\t\t\tid = row[4]\n",
    "\t\t\tif(id == '3950'):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tstartX = row[5]\n",
    "\t\t\tmatch = re.search(r'[-+]?\\d*\\.\\d+|\\d+', startX)\n",
    "\t\t\tx_value = match.group(0)\n",
    "\t\t\tstartY = row[6]\n",
    "\t\t\tmatch2 = re.search(r'[-+]?\\d*\\.\\d+|\\d+', startY)\n",
    "\t\t\ty_value = match2.group(0)\n",
    "\t\t\tendX = row[7]\n",
    "\t\t\tmatch3 = re.search(r'[-+]?\\d*\\.\\d+|\\d+', endX)\n",
    "\t\t\tx_end = match3.group(0)\n",
    "\t\t\tendY = row[8]\n",
    "\t\t\tmatch4 = re.search(r'[-+]?\\d*\\.\\d+|\\d+', endY)\n",
    "\t\t\ty_end = match4.group(0)\n",
    "\t\t\timagePath = os.path.sep.join([IMAGES_PATH, label_value,\n",
    "\t\t\timgFile])\n",
    "\t\t\timage = cv2.imread(imagePath)\n",
    "\t\t\t(h, w) = image.shape[:2]\n",
    "\t\t\tstartX = (float(x_value) / 100)\n",
    "\t\t\tstartY = (float(y_value) / 100)\n",
    "\t\t\tendX = ((float(x_end) + float(x_value)) / 100)\n",
    "\t\t\tendY = ((float(y_end) + float(y_value)) / 100)\n",
    "\t\t\timage = cv2.imread(imagePath)\n",
    "\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\t\timage = cv2.resize(image, (224, 224))\n",
    "\t\t\tdata.append(image)\n",
    "\t\t\tlabels.append(label_value)\n",
    "\t\t\tbboxes.append((startX, startY, endX, endY))\n",
    "\t\t\timagePaths.append(imagePath)\n",
    "\t\t\t\n",
    "\n",
    "labels_test = labels\n",
    "image_test = imagePaths\n",
    "data_test = data\n",
    "bbox_test = bboxes\n",
    "# convert the data, class labels, bounding boxes, and image paths to\n",
    "# NumPy arrays\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "bboxes = np.array(bboxes, dtype=\"float32\")\n",
    "imagePaths = np.array(imagePaths)\n",
    "# perform label encoding on the labels\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "split = train_test_split(data, labels, bboxes, imagePaths,\n",
    "\ttest_size=0.20, random_state=42)\n",
    "# unpack the data split\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainLabels, testLabels) = split[2:4]\n",
    "(trainBBoxes, testBBoxes) = split[4:6]\n",
    "(trainPaths, testPaths) = split[6:]\n",
    "\n",
    "# convert NumPy arrays to PyTorch tensors\n",
    "(trainImages, testImages) = torch.tensor(trainImages),\\\n",
    "\ttorch.tensor(testImages)\n",
    "(trainLabels, testLabels) = torch.tensor(trainLabels),\\\n",
    "\ttorch.tensor(testLabels)\n",
    "(trainBBoxes, testBBoxes) = torch.tensor(trainBBoxes),\\\n",
    "\ttorch.tensor(testBBoxes)\n",
    "# define normalization transforms\n",
    "transforms = Transforms.Compose([\n",
    "\tTransforms.ToPILImage(),\n",
    "\tTransforms.ToTensor(),\n",
    "\tTransforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "\n",
    "# convert NumPy arrays to PyTorch datasets\n",
    "trainDS = CustomTensorDataset((trainImages, trainLabels, trainBBoxes),\n",
    "\ttransforms= transforms)\n",
    "testDS = CustomTensorDataset((testImages, testLabels, testBBoxes),\n",
    "\ttransforms=transforms)\n",
    "print(\"[INFO] total training samples: {}...\".format(len(trainDS)))\n",
    "print(\"[INFO] total test samples: {}...\".format(len(testDS)))\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDS) // BATCH_SIZE\n",
    "valSteps = len(testDS) // BATCH_SIZE\n",
    "# create data loaders\n",
    "trainLoader = DataLoader(trainDS, batch_size= BATCH_SIZE,\n",
    "\tshuffle=True, pin_memory= PIN_MEMORY)\n",
    "testLoader = DataLoader(testDS, batch_size= BATCH_SIZE, pin_memory= PIN_MEMORY)\n",
    "\n",
    "\n",
    "# write the testing image paths to disk so that we can use then\n",
    "# when evaluating/testing our object detector\n",
    "print(\"[INFO] saving testing image paths...\")\n",
    "f = open(TEST_PATHS, \"w\")\n",
    "f.write(\"\\n\".join(testPaths))\n",
    "f.close()\n",
    "\n",
    "trainPaths_str = np.array(trainPaths, dtype='<U114')\n",
    "testPaths_str = np.array(testPaths, dtype='<U114')\n",
    "\n",
    "allPaths = np.concatenate((trainPaths_str, testPaths_str))\n",
    "\n",
    "print(\"[INFO] saving image paths...\")\n",
    "f = open(ALL_PATHS, \"w\")\n",
    "f.write(\"\\n\".join(allPaths))\n",
    "f.close()\n",
    "# load the ResNet50 network\n",
    "resnet = resnet50(weights= 'DEFAULT')\n",
    "# freeze all ResNet50 layers so they will *not* be updated during the\n",
    "# training process\n",
    "for param in resnet.parameters():\n",
    "\tparam.requires_grad = False\n",
    "\n",
    "# create our custom object detector model and flash it to the current\n",
    "# device\n",
    "objectDetector = ObjectDetector(resnet, len(le.classes_))\n",
    "objectDetector = objectDetector.to(DEVICE)\n",
    "# define our loss functions\n",
    "classLossFunc = CrossEntropyLoss()\n",
    "bboxLossFunc = MSELoss()\n",
    "# initialize the optimizer, compile the model, and show the model\n",
    "# summary\n",
    "opt = Adam(objectDetector.parameters(), lr=INIT_LR)\n",
    "# print(objectDetector)\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"total_train_loss\": [], \"total_val_loss\": [], \"train_class_acc\": [],\n",
    "\t \"val_class_acc\": []}\n",
    "\n",
    "# loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "for e in tqdm(range(NUM_EPOCHS)):\n",
    "\t# set the model in training mode\n",
    "\tobjectDetector.train()\n",
    "\t# initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalValLoss = 0\n",
    "\t# initialize the number of correct predictions in the training\n",
    "\t# and validation step\n",
    "\ttrainCorrect = 0\n",
    "\tvalCorrect = 0\n",
    "\t# loop over the training set\n",
    "\tfor (images, labels, bboxes) in trainLoader:\n",
    "\t\t# send the input to the device\n",
    "\t\t(images, labels, bboxes) = (images.to(DEVICE),\n",
    "\t\t\tlabels.to(DEVICE), bboxes.to(DEVICE))\n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "\t\tpredictions = objectDetector(images)\n",
    "\t\tbboxLoss = bboxLossFunc(predictions[0], bboxes)\n",
    "\t\tclassLoss = classLossFunc(predictions[1], labels)\n",
    "\t\ttotalLoss = (BBOX * bboxLoss) + (LABELS * classLoss)\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "\t\t# zero out the gradients, perform the backpropagation step,\n",
    "\t\t# and update the weights\n",
    "\t\topt.zero_grad()\n",
    "\t\ttotalLoss.backward()\n",
    "\t\topt.step()\n",
    "\t\t# add the loss to the total training loss so far and\n",
    "\t\t# calculate the number of correct predictions\n",
    "\t\ttotalTrainLoss += totalLoss\n",
    "\t\ttrainCorrect += (predictions[1].argmax(1) == labels).type(\n",
    "\t\t\ttorch.float).sum().item()\n",
    "\t# switch off autograd\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tobjectDetector.eval()\n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (images, labels, bboxes) in testLoader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(images, labels, bboxes) = (images.to(DEVICE),\n",
    "\t\t\t\tlabels.to(DEVICE), bboxes.to(DEVICE))\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tpredictions = objectDetector(images)\n",
    "\t\t\tbboxLoss = bboxLossFunc(predictions[0], bboxes)\n",
    "\t\t\tclassLoss = classLossFunc(predictions[1], labels)\n",
    "\t\t\ttotalLoss = (BBOX * bboxLoss) + \\\n",
    "\t\t\t\t(LABELS * classLoss)\n",
    "\t\t\ttotalValLoss += totalLoss\n",
    "\t\t\t# calculate the number of correct predictions\n",
    "\t\t\tvalCorrect += (predictions[1].argmax(1) == labels).type(\n",
    "\t\t\t\ttorch.float).sum().item()\n",
    "\t# calculate the average training and validation loss\n",
    "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\tavgValLoss = totalValLoss / valSteps\n",
    "\t# calculate the training and validation accuracy\n",
    "\tprint(trainCorrect, len(trainDS))\n",
    "\tprint(valCorrect, len(testDS))\n",
    "\ttrainCorrect = trainCorrect / len(trainDS)\n",
    "\tvalCorrect = valCorrect / len(testDS)\n",
    "\t# update our training history\n",
    "\tH[\"total_train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "\tH[\"train_class_acc\"].append(trainCorrect)\n",
    "\tH[\"total_val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "\tH[\"val_class_acc\"].append(valCorrect)\n",
    "\t# print the model training and validation information\n",
    "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
    "\tprint(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
    "\t\tavgTrainLoss, trainCorrect))\n",
    "\tprint(\"Val loss: {:.6f}, Val accuracy: {:.4f}\".format(\n",
    "\t\tavgValLoss, valCorrect))\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "\tendTime - startTime))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving object detector model...\")\n",
    "torch.save(objectDetector, MODEL_PATH)\n",
    "# serialize the label encoder to disk\n",
    "print(\"[INFO] saving label encoder...\")\n",
    "f = open(LE_PATH, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"total_train_loss\"], label=\"total_train_loss\")\n",
    "plt.plot(H[\"total_val_loss\"], label=\"total_val_loss\")\n",
    "plt.plot(H[\"train_class_acc\"], label=\"train_class_acc\")\n",
    "plt.plot(H[\"val_class_acc\"], label=\"val_class_acc\")\n",
    "plt.title(\"Total Training Loss and Classification Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "# save the training plot\n",
    "plotPath = os.path.sep.join([PLOTS_PATH, \"training.png\"])\n",
    "plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading object detector...\n"
     ]
    }
   ],
   "source": [
    "# # construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--input\", required=True,\n",
    "# \thelp=\"path to input image/text file of image paths\")\n",
    "# args = vars(ap.parse_args())\n",
    "# # determine the input file type, but assume that we're working with\n",
    "# # single input image\n",
    "# filetype = mimetypes.guess_type(args[\"input\"])[0]\n",
    "imagePaths = open(\"image_paths.txt\").read().strip().split(\"\\n\")\n",
    "# if the file type is a text file, then we need to process *multiple*\n",
    "# images\n",
    "# if \"text/plain\" == filetype:\n",
    "# \t# load the image paths in our testing file\n",
    "# \timagePaths = open(args[\"input\"]).read().strip().split(\"\\n\")\n",
    "\n",
    "print(\"[INFO] loading object detector...\")\n",
    "model = torch.load(MODEL_PATH).to(DEVICE)\n",
    "model.eval()\n",
    "le = pickle.loads(open(LE_PATH, \"rb\").read())\n",
    "# define normalization transforms\n",
    "# transforms = transforms.Compose([\n",
    "# \ttransforms.ToPILImage(),\n",
    "# \ttransforms.ToTensor(),\n",
    "# \ttransforms.Normalize(mean=MEAN, std=STD)\n",
    "# ])\n",
    "bbox_result = []\n",
    "data_image = []\n",
    "# loop over the images that we'll be testing using our bounding box\n",
    "# regression model\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image, copy it, swap its colors channels, resize it, and\n",
    "\t# bring its channel dimension forward\n",
    "\timage_data = cv2.imread(imagePath)\n",
    "\timage = cv2.imread(imagePath)\n",
    "\torig = image.copy()\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (256, 256))\n",
    "\timage = image.transpose((2, 0, 1))\n",
    "\t# convert image to PyTorch tensor, normalize it, flash it to the\n",
    "\t# current device, and add a batch dimension\n",
    "\timage = torch.from_numpy(image)\n",
    "\timage = transforms(image).to(DEVICE)\n",
    "\timage = image.unsqueeze(0)\n",
    "\t# predict the bounding box of the object along with the class\n",
    "\t# label\n",
    "\t(boxPreds, labelPreds) = model(image)\n",
    "\t(startX, startY, endX, endY) = boxPreds[0]\n",
    "\t# determine the class label with the largest predicted\n",
    "\t# probability\n",
    "\tlabelPreds = torch.nn.Softmax(dim=-1)(labelPreds)\n",
    "\ti = labelPreds.argmax(dim=-1).cpu()\n",
    "\tlabel = le.inverse_transform(i)[0]\n",
    "\t# resize the original image such that it fits on our screen, and\n",
    "\t# grab its dimensions\n",
    "\torig = imutils.resize(orig, width=300)\n",
    "\t(h, w) = orig.shape[:2]\n",
    "\t# scale the predicted bounding box coordinates based on the image\n",
    "\t# dimensions\n",
    "\tstartX = int(startX * w)\n",
    "\tstartY = int(startY * h)\n",
    "\tendX = int(endX * w)\n",
    "\tendY = int(endY * h)\n",
    "\t# print(startX,startY,endX,endY)\n",
    "\t# draw the predicted bounding box and class label on the image\n",
    "\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\tcv2.putText(orig, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t0.65, (0, 255, 0), 2)\n",
    "\tcv2.rectangle(orig, (startX, startY), (endX, endY),\n",
    "\t\t(0, 255, 0), 2)\n",
    "\tbboxes = boxPreds[0].detach().cpu().numpy()\n",
    "\tbboxes_str = np.array2string(bboxes)\n",
    "\tbbox_result.append(bboxes_str)\n",
    "\tdata_image.append(image_data)\n",
    "\t# show the output image \n",
    "\t# cv2.imshow(\"Output\", orig)\n",
    "\t# cv2.waitKey(0)\n",
    "\n",
    "f = open(PREDICT_PATHS, \"w\")\n",
    "f.write(\"\\n\".join(bbox_result))\n",
    "f.close()\n",
    "\n",
    "with open(PREDICT_PATHS, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "content = content.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "\n",
    "with open(PREDICT_PATHS, \"w\") as file:\n",
    "    file.write(content)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loop over all CSV files in the annotations directory\n",
    "# for csvPath in paths.list_files(ANNOTS_PATH, validExts=(\".csv\")):\n",
    "# \t# load the contents of the current CSV annotations file\n",
    "# \trows = open(csvPath).read().strip().split(\"\\n\")\n",
    "# \t# loop over the rows\n",
    "# \tfor row in rows:\n",
    "# \t\t# break the row into the filename, bounding box coordinates,\n",
    "# \t\t# and class label\n",
    "# \t\trow = row.split(\",\")\n",
    "\n",
    "\n",
    "# \t\tif len(row) > 8 :\n",
    "# \t\t\tlabel = row[10]\n",
    "# \t\t\tparts = label.split('[')\n",
    "# \t\t\tlabel_value = parts[1].split('\"')[1]\n",
    "\t\t\t\n",
    "# \t\t\tfilename = row[3]\n",
    "# \t\t\tparts2 = filename.split(\"/\")\n",
    "# \t\t\timgFile = \"/\".join(parts2[4:])\n",
    "# \t\t\tid = row[4]\n",
    "# \t\t\tif(id == '3950'):\n",
    "# \t\t\t\tcontinue\n",
    "# \t\t\tstartX = row[5]\n",
    "# \t\t\tmatch = re.search(r'[-+]?\\d*\\.\\d+|\\d+', startX)\n",
    "# \t\t\tx_value = match.group(0)\n",
    "# \t\t\tstartY = row[6]\n",
    "# \t\t\tmatch2 = re.search(r'[-+]?\\d*\\.\\d+|\\d+', startY)\n",
    "# \t\t\ty_value = match2.group(0)\n",
    "# \t\t\tendX = row[7]\n",
    "# \t\t\tmatch3 = re.search(r'[-+]?\\d*\\.\\d+|\\d+', endX)\n",
    "# \t\t\tx_end = match3.group(0)\n",
    "# \t\t\tendY = row[8]\n",
    "# \t\t\tmatch4 = re.search(r'[-+]?\\d*\\.\\d+|\\d+', endY)\n",
    "# \t\t\ty_end = match4.group(0)\n",
    "# \t\t\timagePath = os.path.sep.join([IMAGES_PATH, label_value,\n",
    "# \t\t\timgFile])\n",
    "# \t\t\timage = cv2.imread(imagePath)\n",
    "# \t\t\t(h, w) = image.shape[:2]\n",
    "# \t\t\tstartX = (float(x_value) / 100) * 256\n",
    "# \t\t\tstartY = (float(y_value) / 100) * 256\n",
    "# \t\t\tendX = ((float(x_end) + float(x_value)) / 100) * 256\n",
    "# \t\t\tendY = ((float(y_end) + float(y_value)) / 100) * 256\n",
    "# \t\t\timage = cv2.imread(imagePath)\n",
    "# \t\t\t# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# \t\t\timage = cv2.resize(image, (256, 256))\n",
    "# \t\t\tdata.append(image)\n",
    "# \t\t\tlabels.append(label_value)\n",
    "# \t\t\tbboxes.append((startX, startY, endX, endY))\n",
    "# \t\t\timagePaths.append(imagePath)\n",
    "\t\t\t\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert the data, class labels, bounding boxes, and image paths to\n",
    "# # NumPy arrays\n",
    "# data = np.array(data, dtype=\"float32\")\n",
    "# labels = np.array(labels)\n",
    "# bboxes = np.array(bboxes, dtype=\"float32\")\n",
    "# imagePaths = np.array(imagePaths)\n",
    "# # perform label encoding on the labels\n",
    "# le = LabelEncoder()\n",
    "# labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PREDICT_PATHS, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "with open(ALL_PATHS, \"r\") as file:\n",
    "    liness = file.readlines()\n",
    "\n",
    "bbox_array = []\n",
    "path_array = []\n",
    "\n",
    "for line in lines:\n",
    "    bbox_values = line.split()\n",
    "    bbox_values = [float(value) for value in bbox_values]\n",
    "    (x1,y1,x2,y2) = bbox_values\n",
    "    bbox_array.append((x1,y1,x2,y2))\n",
    "\n",
    "for liness in liness:\n",
    "    path_values = liness.split()\n",
    "    path_array.append(path_values)\n",
    "\n",
    "# print(bbox_array)\n",
    "# print(bbox_test)\n",
    "\n",
    "\n",
    "path_arrays = ([item for sublist in path_array for item in sublist])\n",
    "# print(path_arrays)\n",
    "# print(image_test)\n",
    "\n",
    "for i in range(len(data_image)):\n",
    "    image = data_image[i]\n",
    "    label = labels_test[i]\n",
    "    bbox = bbox_array[i]\n",
    "    imagePath = path_arrays[i]\n",
    "    imageShape = cv2.imread(imagePath)\n",
    "    (h, w) = imageShape.shape[:2]\n",
    "    \n",
    "\n",
    "    # Draw bounding box on the image\n",
    "    startX, startY, endX, endY = bbox\n",
    "    # print(startX,startY,endX,endY)\n",
    "    startX = startX * w\n",
    "    startY = startY * h\n",
    "    endX = endX * w\n",
    "    endY = endY * h\n",
    "    # print(startX,startY,endX,endY)\n",
    "\n",
    "    crop_path = os.path.join('crop', os.path.basename(imagePath))\n",
    "    crop_image = image[int(startY):int(endY), int(startX):int(endX)]\n",
    "    cv2.imwrite(crop_path, crop_image)\n",
    "\n",
    "\n",
    "    cv2.rectangle(image, (int(startX), int(startY)), (int(endX), int(endY)), (0, 255, 0), 3)\n",
    "    output_path = os.path.join('gambar', os.path.basename(imagePath))\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset\\\\images\\\\chicken\\\\1db97a01-60010-1670724835.png', 'dataset\\\\images\\\\chicken\\\\a4e42f49-60010-1671179498.png', 'dataset\\\\images\\\\chicken\\\\0c2ae7a4-60010-1670840908.png', 'dataset\\\\images\\\\chicken\\\\8f0120c3-60010-1671526813.png', 'dataset\\\\images\\\\chicken\\\\19e404cf-60010-1670806980.png', 'dataset\\\\images\\\\chicken\\\\3a71351e-60010-1671615634.png', 'dataset\\\\images\\\\chicken\\\\ecbeca9b-60010-1670724836.png', 'dataset\\\\images\\\\chicken\\\\74c607da-60010-1671527849.png', 'dataset\\\\images\\\\chicken\\\\8da079e4-60010-1670636695.png', 'dataset\\\\images\\\\chicken\\\\8756d357-60010-1670933753.png', 'dataset\\\\images\\\\chicken\\\\e35f0df8-60010-1670656648.png', 'dataset\\\\images\\\\chicken\\\\81e9ab89-60010-1671528566.png', 'dataset\\\\images\\\\chicken\\\\d96906d8-60010-1671111643.png', 'dataset\\\\images\\\\chicken\\\\3d85d518-60010-1670724845.png', 'dataset\\\\images\\\\chicken\\\\abdf397f-60010-1671528111.png', 'dataset\\\\images\\\\chicken\\\\57f93ea4-60010-1671526674.png', 'dataset\\\\images\\\\chicken\\\\ec322a1b-60010-1670724832.png', 'dataset\\\\images\\\\chicken\\\\4db4ec15-60010-1671179585.png', 'dataset\\\\images\\\\chicken\\\\798176e7-60010-1671022739.png', 'dataset\\\\images\\\\chicken\\\\68f7e053-60010-1671615909.png', 'dataset\\\\images\\\\chicken\\\\f48d2662-60010-1670643929.png', 'dataset\\\\images\\\\chicken\\\\22aeb985-60010-1670722902.png', 'dataset\\\\images\\\\chicken\\\\72a12bc9-60010-1670933719.png', 'dataset\\\\images\\\\chicken\\\\f94da4d7-60010-1670656243.png', 'dataset\\\\images\\\\chicken\\\\8a4ce1ec-60010-1671526723.png', 'dataset\\\\images\\\\chicken\\\\724ac8d1-60010-1670840874.png', 'dataset\\\\images\\\\chicken\\\\6531c9fc-60010-1670933768.png', 'dataset\\\\images\\\\chicken\\\\fed63bf1-60010-1671527291.png', 'dataset\\\\images\\\\chicken\\\\1d046d19-60010-1670643912.png', 'dataset\\\\images\\\\chicken\\\\1992886e-60010-1671022780.png', 'dataset\\\\images\\\\chicken\\\\975884ae-60010-1670840868.png', 'dataset\\\\images\\\\chicken\\\\cbc3c969-60010-1670933717.png', 'dataset\\\\images\\\\chicken\\\\45ffa2f2-60010-1670933745.png', 'dataset\\\\images\\\\chicken\\\\4062d1a0-60010-1671614425.png', 'dataset\\\\images\\\\chicken\\\\78a375a6-60010-1670722925.png', 'dataset\\\\images\\\\chicken\\\\4a616ab7-60010-1670657010.png', 'dataset\\\\images\\\\chicken\\\\9a6855be-60010-1670643938.png', 'dataset\\\\images\\\\chicken\\\\6ad256a8-60010-1671022775.png', 'dataset\\\\images\\\\chicken\\\\c8f0ba14-60010-1671528230.png', 'dataset\\\\images\\\\chicken\\\\4bda8750-60010-1671615071.png', 'dataset\\\\images\\\\chicken\\\\ef001331-60010-1671614048.png', 'dataset\\\\images\\\\chicken\\\\149c1eb7-60010-1671614950.png', 'dataset\\\\images\\\\chicken\\\\15f593c6-60010-1670933728.png', 'dataset\\\\images\\\\chicken\\\\55b7f92e-60010-1670724839.png', 'dataset\\\\images\\\\chicken\\\\605dd4b6-60010-1671178387.png', 'dataset\\\\images\\\\chicken\\\\087ccaba-60010-1670840879.png', 'dataset\\\\images\\\\chicken\\\\11ce3b73-60010-1670643906.png', 'dataset\\\\images\\\\chicken\\\\7c7bd3ee-60010-1671527018.png', 'dataset\\\\images\\\\chicken\\\\316f65b0-60010-1671178492.png', 'dataset\\\\images\\\\chicken\\\\452992f7-60010-1670933721.png', 'dataset\\\\images\\\\chicken\\\\ebeb8aa7-60010-1671448481.png', 'dataset\\\\images\\\\chicken\\\\140a7822-60010-1670657044.png', 'dataset\\\\images\\\\chicken\\\\375d1077-60010-1670656418.png', 'dataset\\\\images\\\\chicken\\\\dbdc747b-60010-1670840871.png', 'dataset\\\\images\\\\chicken\\\\0e29c6f3-60010-1671177297.png', 'dataset\\\\images\\\\chicken\\\\eeec33ce-60010-1670643917.png', 'dataset\\\\images\\\\chicken\\\\54632413-60010-1670840892_2.png', 'dataset\\\\images\\\\chicken\\\\3296c9cd-60010-1671178349.png', 'dataset\\\\images\\\\chicken\\\\24384b23-60010-1671526917.png', 'dataset\\\\images\\\\chicken\\\\8034bfbe-60010-1671528344.png', 'dataset\\\\images\\\\chicken\\\\79854e3b-60010-1670806995.png', 'dataset\\\\images\\\\chicken\\\\13c107da-60010-1671448487_2.png', 'dataset\\\\images\\\\chicken\\\\569e8bae-60010-1671022779.png', 'dataset\\\\images\\\\chicken\\\\61acdd7b-60010-1671613798.png', 'dataset\\\\images\\\\chicken\\\\1915f1ee-60010-1671022727.png', 'dataset\\\\images\\\\chicken\\\\3b8d5353-60010-1671179259.png', 'dataset\\\\images\\\\chicken\\\\f9cc3388-60010-1670840881_2.png', 'dataset\\\\images\\\\chicken\\\\41fd55a5-60010-1671177448.png', 'dataset\\\\images\\\\chicken\\\\3260ed18-60010-1670840872_2.png', 'dataset\\\\images\\\\chicken\\\\1db5b227-60010-1671527829.png', 'dataset\\\\images\\\\chicken\\\\06c14cb3-60010-1671111651.png', 'dataset\\\\images\\\\chicken\\\\2f640c12-60010-1670806990.png', 'dataset\\\\images\\\\chicken\\\\82603615-60010-1671527400.png', 'dataset\\\\images\\\\chicken\\\\609c7609-60010-1670840915.png', 'dataset\\\\images\\\\chicken\\\\2b9e0836-60010-1671527066.png', 'dataset\\\\images\\\\chicken\\\\f2cb9b42-60010-1670840911.png', 'dataset\\\\images\\\\chicken\\\\c760b512-60010-1670724837.png', 'dataset\\\\images\\\\chicken\\\\5c6a648b-60010-1670840885.png', 'dataset\\\\images\\\\chicken\\\\f49b2ab1-60010-1671615611.png', 'dataset\\\\images\\\\chicken\\\\763494ba-60010-1671614358.png', 'dataset\\\\images\\\\chicken\\\\b0fbee6b-60010-1670806979.png', 'dataset\\\\images\\\\chicken\\\\5bd54292-60010-1671528156.png', 'dataset\\\\images\\\\chicken\\\\d06018df-60010-1671614128.png', 'dataset\\\\images\\\\chicken\\\\3c160174-60010-1671448487.png', 'dataset\\\\images\\\\chicken\\\\93412420-60010-1671022765.png', 'dataset\\\\images\\\\chicken\\\\d2fdfc99-60010-1670933739.png', 'dataset\\\\images\\\\chicken\\\\b6da4858-60010-1671179584.png', 'dataset\\\\images\\\\chicken\\\\cebd0c29-60010-1671528749.png', 'dataset\\\\images\\\\chicken\\\\264f4c48-60010-1670722804.png', 'dataset\\\\images\\\\chicken\\\\b63ed291-60010-1670723013.png', 'dataset\\\\images\\\\chicken\\\\c9ddcc15-60010-1671614585.png', 'dataset\\\\images\\\\chicken\\\\e9445578-60010-1671615829.png', 'dataset\\\\images\\\\chicken\\\\3b0a1354-60010-1671614565.png', 'dataset\\\\images\\\\chicken\\\\a8858306-60010-1670933723.png', 'dataset\\\\images\\\\chicken\\\\5db69440-60010-1670657261.png', 'dataset\\\\images\\\\chicken\\\\ebbf45a0-60010-1670636775.png', 'dataset\\\\images\\\\chicken\\\\d1529bc9-60010-1670657206.png', 'dataset\\\\images\\\\chicken\\\\de41bb00-60010-1671527572.png', 'dataset\\\\images\\\\chicken\\\\d1b6ab5c-60010-1671022733.png', 'dataset\\\\images\\\\chicken\\\\36dd416d-60010-1671177338.png', 'dataset\\\\images\\\\chicken\\\\c6b1c68a-60010-1671615280.png', 'dataset\\\\images\\\\chicken\\\\3978daec-60010-1671528370.png', 'dataset\\\\images\\\\chicken\\\\ac1c2198-60010-1671527455.png', 'dataset\\\\images\\\\chicken\\\\1de65e6b-60010-1671177190.png', 'dataset\\\\images\\\\chicken\\\\b8e27d09-60010-1671693190.png', 'dataset\\\\images\\\\chicken\\\\f33fc1d0-60010-1670643898.png', 'dataset\\\\images\\\\chicken\\\\f913d2f5-60010-1670724840.png', 'dataset\\\\images\\\\chicken\\\\253d65e2-60010-1670643916.png', 'dataset\\\\images\\\\chicken\\\\6c48bd77-60010-1670643931.png', 'dataset\\\\images\\\\chicken\\\\6d4f3197-60010-1670643930.png', 'dataset\\\\images\\\\chicken\\\\02ab6ceb-60010-1670806982.png', 'dataset\\\\images\\\\chicken\\\\02e6afb5-60010-1671614073.png', 'dataset\\\\images\\\\chicken\\\\cf6b6a47-60010-1670933770_2.png', 'dataset\\\\images\\\\chicken\\\\47160bc3-60010-1670806992.png', 'dataset\\\\images\\\\chicken\\\\f905b6c2-60010-1671179005.png', 'dataset\\\\images\\\\chicken\\\\8d4a5d1a-60010-1671692942.png', 'dataset\\\\images\\\\chicken\\\\484c871b-60010-1670806991.png', 'dataset\\\\images\\\\chicken\\\\a4740a47-60010-1671448490.png', 'dataset\\\\images\\\\chicken\\\\b8e79d7a-60010-1671448498.png', 'dataset\\\\images\\\\chicken\\\\2b0ba95f-60010-1670840910.png', 'dataset\\\\images\\\\chicken\\\\5603b4b3-60010-1671022759.png', 'dataset\\\\images\\\\chicken\\\\5f5665ca-60010-1670643902.png', 'dataset\\\\images\\\\chicken\\\\ab9c56dd-60010-1671177379.png', 'dataset\\\\images\\\\chicken\\\\485453d7-60010-1670840909.png', 'dataset\\\\images\\\\chicken\\\\ef40940c-60010-1671615955.png', 'dataset\\\\images\\\\chicken\\\\f3a0c3e4-60010-1670933754.png', 'dataset\\\\images\\\\chicken\\\\4fb4035c-60010-1671022766.png', 'dataset\\\\images\\\\chicken\\\\0a4cfef2-60010-1671179648.png', 'dataset\\\\images\\\\chicken\\\\aefac755-60010-1671022720.png', 'dataset\\\\images\\\\chicken\\\\ae00acfd-60010-1671178542.png', 'dataset\\\\images\\\\chicken\\\\ae92fa3e-60010-1671527493.png', 'dataset\\\\images\\\\chicken\\\\5e145703-60010-1670643896.png', 'dataset\\\\images\\\\chicken\\\\d370e32f-60010-1670840904.png', 'dataset\\\\images\\\\chicken\\\\16aed579-60010-1670643910.png', 'dataset\\\\images\\\\chicken\\\\71ab293c-60010-1670840881.png', 'dataset\\\\images\\\\chicken\\\\add87ef6-60010-1671448482.png', 'dataset\\\\images\\\\chicken\\\\16c8d6d7-60010-1671694907.png', 'dataset\\\\images\\\\chicken\\\\cf4a2208-60010-1671022753.png', 'dataset\\\\images\\\\chicken\\\\4aa5f44f-60010-1671528696.png', 'dataset\\\\images\\\\chicken\\\\9e7ff8a9-60010-1670840867.png', 'dataset\\\\images\\\\chicken\\\\e03f84f3-60010-1671178706.png', 'dataset\\\\images\\\\chicken\\\\a900313c-60010-1670657289.png', 'dataset\\\\images\\\\chicken\\\\a6be9a39-60010-1670933762.png', 'dataset\\\\images\\\\chicken\\\\e0cece79-60010-1670933727_2.png', 'dataset\\\\images\\\\chicken\\\\82b5ba5b-60010-1671177242.png', 'dataset\\\\images\\\\chicken\\\\81a2db29-60010-1670840931.png', 'dataset\\\\images\\\\chicken\\\\9c3b12d2-60010-1670806997.png', 'dataset\\\\images\\\\chicken\\\\54bdb0d3-60010-1671613851.png', 'dataset\\\\images\\\\chicken\\\\5720f688-60010-1670933759.png', 'dataset\\\\images\\\\chicken\\\\8deb2ea5-60010-1670724853.png', 'dataset\\\\images\\\\chicken\\\\22836d17-60010-1670656725.png', 'dataset\\\\images\\\\chicken\\\\880011b4-60010-1671022751.png', 'dataset\\\\images\\\\chicken\\\\972c7fde-60010-1670840925.png', 'dataset\\\\images\\\\chicken\\\\cc831202-60010-1670656568.png', 'dataset\\\\images\\\\chicken\\\\5050268b-60010-1671177326.png', 'dataset\\\\images\\\\chicken\\\\c6f75dc5-60010-1670807001.png', 'dataset\\\\images\\\\chicken\\\\d7792c06-60010-1670840921_2.png', 'dataset\\\\images\\\\chicken\\\\05c8c9d0-60010-1670840892.png', 'dataset\\\\images\\\\chicken\\\\a1c76e3e-60010-1670657185.png', 'dataset\\\\images\\\\chicken\\\\1b705219-60010-1671529114.png', 'dataset\\\\images\\\\chicken\\\\bae8c0bb-60010-1670723072.png', 'dataset\\\\images\\\\chicken\\\\7104beec-60010-1670723269.png', 'dataset\\\\images\\\\chicken\\\\cdb14f1d-60010-1671528518.png', 'dataset\\\\images\\\\chicken\\\\62bd960b-60010-1670933716.png', 'dataset\\\\images\\\\chicken\\\\1645cdd3-60010-1670840894.png', 'dataset\\\\images\\\\chicken\\\\e22834ec-60010-1670569029.png', 'dataset\\\\images\\\\chicken\\\\c10cea3e-60010-1671695133.png', 'dataset\\\\images\\\\chicken\\\\400a91f4-60010-1671178600.png', 'dataset\\\\images\\\\chicken\\\\30cf252c-60010-1671613991.png', 'dataset\\\\images\\\\chicken\\\\905dd08a-60010-1671022761.png', 'dataset\\\\images\\\\chicken\\\\972c7fde-60010-1670840925.png', 'dataset\\\\images\\\\chicken\\\\516bd868-60010-1671527886.png', 'dataset\\\\images\\\\chicken\\\\3b3653c5-60010-1670723052.png', 'dataset\\\\images\\\\chicken\\\\93d653ce-60010-1670840886_2.png', 'dataset\\\\images\\\\chicken\\\\e65f11fc-60010-1671022723.png', 'dataset\\\\images\\\\chicken\\\\22cfd7d9-60010-1671177507.png', 'dataset\\\\images\\\\chicken\\\\01e0cef1-60010-1670840923.png', 'dataset\\\\images\\\\chicken\\\\c625a60c-60010-1670933744.png', 'dataset\\\\images\\\\chicken\\\\6fed5f93-60010-1671613879.png', 'dataset\\\\images\\\\chicken\\\\e7347c67-60010-1670724844.png', 'dataset\\\\images\\\\chicken\\\\55ac3c46-60010-1671177423.png', 'dataset\\\\images\\\\chicken\\\\58a7fac5-60010-1671177215.png', 'dataset\\\\images\\\\chicken\\\\255e83fd-60010-1671694879.png', 'dataset\\\\images\\\\chicken\\\\f8f1ea80-60010-1671527039.png', 'dataset\\\\images\\\\chicken\\\\6f0a289b-60010-1670840918.png', 'dataset\\\\images\\\\chicken\\\\af2e9a07-60010-1671526639.png', 'dataset\\\\images\\\\chicken\\\\deb7bab3-60010-1670933733.png', 'dataset\\\\images\\\\chicken\\\\a18be70a-60010-1670933735.png', 'dataset\\\\images\\\\chicken\\\\ee612484-60010-1670643933.png', 'dataset\\\\images\\\\chicken\\\\985846ac-60010-1670840913_2.png', 'dataset\\\\images\\\\chicken\\\\f0f39afb-60010-1670807008.png', 'dataset\\\\images\\\\chicken\\\\197b9597-what-are-broiler-chickens-the-humane-league.jpg', 'dataset\\\\images\\\\chicken\\\\ed067e30-60010-1671695154.png', 'dataset\\\\images\\\\chicken\\\\418d24a6-60010-1670722891.png', 'dataset\\\\images\\\\chicken\\\\88354d38-60010-1670656370.png', 'dataset\\\\images\\\\chicken\\\\ca88c6ed-60010-1671527423.png', 'dataset\\\\images\\\\chicken\\\\86b26e38-60010-1671022740.png', 'dataset\\\\images\\\\chicken\\\\99fc00c5-60010-1670657459.png', 'dataset\\\\images\\\\chicken\\\\ca16d9ef-60010-1671693049.png', 'dataset\\\\images\\\\chicken\\\\1759975d-60010-1671614521.png', 'dataset\\\\images\\\\chicken\\\\91d64a85-60010-1671526994.png', 'dataset\\\\images\\\\chicken\\\\271e9b23-60010-1671022752.png', 'dataset\\\\images\\\\chicken\\\\47160bc3-60010-1670806992.png', 'dataset\\\\images\\\\chicken\\\\3ed0d0f7-60010-1670933730.png', 'dataset\\\\images\\\\chicken\\\\42821a5b-60010-1671022732.png', 'dataset\\\\images\\\\chicken\\\\fb14d268-60010-1671022770.png', 'dataset\\\\images\\\\chicken\\\\2a7900af-60010-1671693025.png', 'dataset\\\\images\\\\chicken\\\\28688b26-60010-1670724849.png', 'dataset\\\\images\\\\chicken\\\\399dc10f-60010-1670723247.png', 'dataset\\\\images\\\\chicken\\\\c30eebbb-60010-1671528106.png', 'dataset\\\\images\\\\chicken\\\\cbfbeaa2-60010-1671613933.png', 'dataset\\\\images\\\\chicken\\\\2ed36fea-60010-1670806998.png', 'dataset\\\\images\\\\chicken\\\\9a39665d-60010-1671448479_2.png', 'dataset\\\\images\\\\chicken\\\\a2efdfb9-60010-1671178574.png', 'dataset\\\\images\\\\chicken\\\\6e7c64de-60010-1671528654.png', 'dataset\\\\images\\\\chicken\\\\53128014-60010-1671694983.png', 'dataset\\\\images\\\\chicken\\\\62985347-60010-1671022764.png', 'dataset\\\\images\\\\chicken\\\\2149ae72-60010-1670933747.png', 'dataset\\\\images\\\\chicken\\\\a2dcfec5-60010-1671022724.png', 'dataset\\\\images\\\\chicken\\\\8970a831-60010-1671615180.png', 'dataset\\\\images\\\\chicken\\\\2d45cf20-60010-1670724842.png', 'dataset\\\\images\\\\chicken\\\\0f620f7f-60010-1670724841.png', 'dataset\\\\images\\\\chicken\\\\de5932c9-60010-1671528500.png', 'dataset\\\\images\\\\chicken\\\\f2b828a3-60010-1670933746.png', 'dataset\\\\images\\\\chicken\\\\864c07a3-60010-1670643907.png', 'dataset\\\\images\\\\chicken\\\\77c14f3f-60010-1670806987.png', 'dataset\\\\images\\\\chicken\\\\30a1833c-60010-1671528413.png', 'dataset\\\\images\\\\chicken\\\\401f9b0f-60010-1670933737.png', 'dataset\\\\images\\\\chicken\\\\51a4de52-60010-1671615331.png', 'dataset\\\\images\\\\chicken\\\\14fb212f-60010-1670643899.png', 'dataset\\\\images\\\\chicken\\\\af4c7c6c-60010-1670933731.png', 'dataset\\\\images\\\\chicken\\\\406e8f56-60010-1671022725.png', 'dataset\\\\images\\\\chicken\\\\7c5d2aa0-60010-1670643913.png', 'dataset\\\\images\\\\chicken\\\\aadd83b2-60010-1671527378.png', 'dataset\\\\images\\\\chicken\\\\328c6a81-60010-1670806984.png', 'dataset\\\\images\\\\chicken\\\\f5f5302c-60010-1670643926.png', 'dataset\\\\images\\\\chicken\\\\702fd8fd-60010-1671178987.png', 'dataset\\\\images\\\\chicken\\\\f18def9c-60010-1670840901.png', 'dataset\\\\images\\\\chicken\\\\ee5f371a-60010-1670933725.png', 'dataset\\\\images\\\\chicken\\\\ceb9a202-60010-1671613705.png', 'dataset\\\\images\\\\chicken\\\\ce841fa8-60010-1670840921.png', 'dataset\\\\images\\\\chicken\\\\050d7094-60010-1671692944.png', 'dataset\\\\images\\\\chicken\\\\6e5c53cd-60010-1670724855.png', 'dataset\\\\images\\\\chicken\\\\46708da4-60010-1670723450.png', 'dataset\\\\images\\\\chicken\\\\ca4ad585-60010-1671526746.png', 'dataset\\\\images\\\\chicken\\\\6531c9fc-60010-1670933768.png', 'dataset\\\\images\\\\chicken\\\\d1e45ee9-60010-1670933714.png', 'dataset\\\\images\\\\chicken\\\\f484dae6-60010-1670722990.png', 'dataset\\\\images\\\\chicken\\\\728f2d57-60010-1671176898.png', 'dataset\\\\images\\\\chicken\\\\1ca88cbf-60010-1670806988.png', 'dataset\\\\images\\\\chicken\\\\b72283d0-60010-1671022730.png', 'dataset\\\\images\\\\chicken\\\\f52ac42d-60010-1671022776.png', 'dataset\\\\images\\\\chicken\\\\24d2b999-60010-1670656296.png', 'dataset\\\\images\\\\chicken\\\\c62cbbc6-60010-1671448490_2.png', 'dataset\\\\images\\\\chicken\\\\71ab293c-60010-1670840881.png', 'dataset\\\\images\\\\chicken\\\\0a31529f-60010-1670840927.png', 'dataset\\\\images\\\\chicken\\\\6e991dda-60010-1670643905.png', 'dataset\\\\images\\\\chicken\\\\9cd819bb-60010-1671694956.png', 'dataset\\\\images\\\\chicken\\\\e902cfb3-60010-1670933749.png', 'dataset\\\\images\\\\chicken\\\\485453d7-60010-1670840909.png', 'dataset\\\\images\\\\chicken\\\\43701cb8-60010-1671179448.png', 'dataset\\\\images\\\\chicken\\\\8d893944-60010-1671692963.png', 'dataset\\\\images\\\\chicken\\\\315a269d-60010-1670807003.png', 'dataset\\\\images\\\\chicken\\\\d7e74118-60010-1671448488_2.png', 'dataset\\\\images\\\\chicken\\\\67c7a19f-60010-1671614333.png', 'dataset\\\\images\\\\chicken\\\\2c085231-60010-1671448485.png', 'dataset\\\\images\\\\chicken\\\\9057b8ec-60010-1670657316.png', 'dataset\\\\images\\\\chicken\\\\cc9efb9f-60010-1670806993.png', 'dataset\\\\images\\\\chicken\\\\a5fb22cb-60010-1670933727.png', 'dataset\\\\images\\\\chicken\\\\ec0c4e8e-60010-1671448478.png', 'dataset\\\\images\\\\chicken\\\\ba92861d-60010-1671528435.png', 'dataset\\\\images\\\\chicken\\\\9ba4b170-60010-1671448499.png', 'dataset\\\\images\\\\chicken\\\\3764c062-60010-1671448495.png', 'dataset\\\\images\\\\chicken\\\\e82277e6-60010-1671614310.png', 'dataset\\\\images\\\\chicken\\\\395aba20-60010-1671448479.png', 'dataset\\\\images\\\\chicken\\\\b4c1c752-60010-1670636649.png', 'dataset\\\\images\\\\chicken\\\\9b08cdac-60010-1671694930.png', 'dataset\\\\images\\\\chicken\\\\b44fbda1-60010-1670643932.png', 'dataset\\\\images\\\\chicken\\\\cde620df-60010-1671178672.png', 'dataset\\\\images\\\\chicken\\\\6d0c564f-60010-1671527519.png', 'dataset\\\\images\\\\chicken\\\\c62e80b1-60010-1670806986.png', 'dataset\\\\images\\\\chicken\\\\f993ac40-60010-1670643903.png', 'dataset\\\\images\\\\chicken\\\\41663497-60010-1670643935.png', 'dataset\\\\images\\\\chicken\\\\d16a28d5-60010-1671693134.png', 'dataset\\\\images\\\\chicken\\\\a2f3674a-60010-1671615048.png', 'dataset\\\\images\\\\chicken\\\\f73eb145-60010-1670636495.png', 'dataset\\\\images\\\\chicken\\\\da028864-60010-1671528178.png', 'dataset\\\\images\\\\chicken\\\\512050ac-60010-1671179344.png', 'dataset\\\\images\\\\chicken\\\\39927bef-60010-1670933741.png', 'dataset\\\\images\\\\chicken\\\\718ae90b-60010-1671615155.png', 'dataset\\\\images\\\\chicken\\\\0da43987-60010-1670840930.png', 'dataset\\\\images\\\\chicken\\\\b12378f5-60010-1670657349.png', 'dataset\\\\images\\\\chicken\\\\31dd0bda-60010-1670840932.png', 'dataset\\\\images\\\\chicken\\\\50bac2b6-60010-1671695108.png', 'dataset\\\\images\\\\chicken\\\\8b3c1e7c-60010-1670840884.png', 'dataset\\\\images\\\\chicken\\\\786be600-60010-1670643914.png', 'dataset\\\\images\\\\chicken\\\\28a823c0-60010-1671528004.png', 'dataset\\\\images\\\\chicken\\\\affa2b34-60010-1670840914.png', 'dataset\\\\images\\\\chicken\\\\203d8588-60010-1671178169.png', 'dataset\\\\images\\\\chicken\\\\476da718-60010-1670643937.png', 'dataset\\\\images\\\\chicken\\\\d4d906e6-60010-1671022735.png', 'dataset\\\\images\\\\chicken\\\\d81101e0-60010-1670840886.png', 'dataset\\\\images\\\\chicken\\\\60687240-60010-1670643925.png', 'dataset\\\\images\\\\chicken\\\\36d81775-60010-1670724858.png', 'dataset\\\\images\\\\chicken\\\\3c5556ba-60010-1670840893.png', 'dataset\\\\images\\\\chicken\\\\1b95b098-60010-1671692986.png', 'dataset\\\\images\\\\chicken\\\\922fc7e9-60010-1671022745.png', 'dataset\\\\images\\\\chicken\\\\374e4c74-60010-1671022741.png', 'dataset\\\\images\\\\chicken\\\\a98e94ff-60010-1671178451.png', 'dataset\\\\images\\\\chicken\\\\c8a3ffe7-60010-1670806989.png', 'dataset\\\\images\\\\chicken\\\\2ef784fe-60010-1671529135.png', 'dataset\\\\images\\\\chicken\\\\3fa6e278-60010-1670723472.png', 'dataset\\\\images\\\\chicken\\\\509e54f7-60010-1671527272.png', 'dataset\\\\images\\\\chicken\\\\a2d5c07c-60010-1670807007.png', 'dataset\\\\images\\\\chicken\\\\66165718-60010-1671529194.png', 'dataset\\\\images\\\\chicken\\\\09cf9dbb-60010-1671613823.png', 'dataset\\\\images\\\\chicken\\\\beb0531c-60010-1671179610.png', 'dataset\\\\images\\\\chicken\\\\55d3d062-60010-1671448491.png', 'dataset\\\\images\\\\chicken\\\\3285267f-60010-1671615803.png', 'dataset\\\\images\\\\chicken\\\\0cea2d1e-60010-1671693107.png', 'dataset\\\\images\\\\chicken\\\\4c829803-60010-1671528658.png', 'dataset\\\\images\\\\chicken\\\\62753b78-60010-1671613765.png', 'dataset\\\\images\\\\chicken\\\\f92daa6a-60010-1670656545.png', 'dataset\\\\images\\\\chicken\\\\62df15d8-60010-1671448489_2.png', 'dataset\\\\images\\\\chicken\\\\f6371788-60010-1670806983.png', 'dataset\\\\images\\\\chicken\\\\47b454e8-60010-1671178516.png', 'dataset\\\\images\\\\chicken\\\\3a795476-60010-1671448493_2.png', 'dataset\\\\images\\\\chicken\\\\6899ebf9-60010-1670806978.png', 'dataset\\\\images\\\\chicken\\\\a44a9ad9-60010-1670933734.png', 'dataset\\\\images\\\\chicken\\\\eb8ae40b-60010-1670807006.png', 'dataset\\\\images\\\\chicken\\\\d917cf7e-60010-1671528392.png', 'dataset\\\\images\\\\chicken\\\\d8581b7a-60010-1671022736.png', 'dataset\\\\images\\\\chicken\\\\bdfe34c5-60010-1671022754.png', 'dataset\\\\images\\\\chicken\\\\87ec4eba-60010-1671694819.png', 'dataset\\\\images\\\\chicken\\\\77935961-60010-1671526942.png', 'dataset\\\\images\\\\chicken\\\\1a73f419-60010-1670724852.png', 'dataset\\\\images\\\\chicken\\\\ef18a372-60010-1671526875.png', 'dataset\\\\images\\\\chicken\\\\fbb75adb-60010-1671526766.png', 'dataset\\\\images\\\\chicken\\\\d2d672b7-60010-1670722946.png', 'dataset\\\\images\\\\chicken\\\\6ef861e7-60010-1670840885_2.png', 'dataset\\\\images\\\\chicken\\\\03fd5fbe-60010-1671448500.png', 'dataset\\\\images\\\\chicken\\\\0caf9307-60010-1671528202.png', 'dataset\\\\images\\\\chicken\\\\264f4c48-60010-1670722804.png', 'dataset\\\\images\\\\chicken\\\\0ef9816a-60010-1671177142.png', 'dataset\\\\images\\\\chicken\\\\8f5bf1af-60010-1671177018.png', 'dataset\\\\images\\\\chicken\\\\6f558105-60010-1671528236.png', 'dataset\\\\images\\\\chicken\\\\79916dfd-60010-1671528342.png', 'dataset\\\\images\\\\chicken\\\\5a159a12-60010-1670656702.png', 'dataset\\\\images\\\\chicken\\\\32ea1be4-60010-1670723033.png', 'dataset\\\\images\\\\chicken\\\\91e79eea-60010-1671022778.png', 'dataset\\\\images\\\\chicken\\\\f2de4b1b-60010-1671693084.png', 'dataset\\\\images\\\\chicken\\\\907f591d-60010-1670723122.png', 'dataset\\\\images\\\\chicken\\\\f215eb60-60010-1670656023.png', 'dataset\\\\images\\\\chicken\\\\f384e05e-60010-1670724851.png', 'dataset\\\\images\\\\chicken\\\\0bec37f3-60010-1671022774.png', 'dataset\\\\images\\\\chicken\\\\d964ec7a-60010-1671615779.png', 'dataset\\\\images\\\\chicken\\\\8b6502d0-60010-1670840870.png', 'dataset\\\\images\\\\chicken\\\\ac9c15c9-60010-1671448501.png', 'dataset\\\\images\\\\chicken\\\\3934d8b6-60010-1671526853.png', 'dataset\\\\images\\\\chicken\\\\406101a4-60010-1671529044.png', 'dataset\\\\images\\\\chicken\\\\19d55e27-60010-1671615852.png', 'dataset\\\\images\\\\chicken\\\\4768c84a-60010-1670643895.png', 'dataset\\\\images\\\\chicken\\\\3b9a8762-60010-1671528771.png', 'dataset\\\\images\\\\chicken\\\\c5fdab13-60010-1671448494.png', 'dataset\\\\images\\\\chicken\\\\c21100af-60010-1671528389.png', 'dataset\\\\images\\\\chicken\\\\b5e11844-60010-1670643924.png', 'dataset\\\\images\\\\chicken\\\\10dcd664-60010-1671178772.png', 'dataset\\\\images\\\\chicken\\\\bc2da085-60010-1670840907.png', 'dataset\\\\images\\\\chicken\\\\7c15a6d1-60010-1670933729.png', 'dataset\\\\images\\\\chicken\\\\baefd864-60010-1671528203.png', 'dataset\\\\images\\\\chicken\\\\872029a7-60010-1671526895.png', 'dataset\\\\images\\\\chicken\\\\bc57a29f-60010-1671527169.png', 'dataset\\\\images\\\\chicken\\\\bd212058-60010-1670840913.png', 'dataset\\\\images\\\\chicken\\\\c4e72bc6-60010-1670933724.png', 'dataset\\\\images\\\\chicken\\\\c35bcee9-60010-1671112191.png', 'dataset\\\\images\\\\chicken\\\\d3c7d055-60010-1670724850.png', 'dataset\\\\images\\\\chicken\\\\5570f8d3-60010-1671528137.png', 'dataset\\\\images\\\\chicken\\\\02a4eeb2-60010-1671614400.png', 'dataset\\\\images\\\\chicken\\\\b4252c3c-60010-1671448483.png', 'dataset\\\\images\\\\chicken\\\\8025199e-60010-1670724847.png', 'dataset\\\\images\\\\chicken\\\\9e4332e5-60010-1670724846.png', 'dataset\\\\images\\\\chicken\\\\dd82093e-60010-1671527190.png', 'dataset\\\\images\\\\chicken\\\\4c12c9e6-60010-1671615253.png', 'dataset\\\\images\\\\chicken\\\\c5e940c3-60010-1671527475.png', 'dataset\\\\images\\\\chicken\\\\222dcd45-60010-1670933772.png', 'dataset\\\\images\\\\chicken\\\\b2c5229a-60010-1671179295.png', 'dataset\\\\images\\\\chicken\\\\75dbd949-60010-1670933752.png', 'dataset\\\\images\\\\chicken\\\\b98c6137-60010-1670806999.png', 'dataset\\\\images\\\\chicken\\\\debbd682-60010-1670723225.png', 'dataset\\\\images\\\\chicken\\\\ca1db553-60010-1671529156.png', 'dataset\\\\images\\\\chicken\\\\73d514fc-60010-1670724843.png', 'dataset\\\\images\\\\chicken\\\\6e1f529e-60010-1671616685.png', 'dataset\\\\images\\\\chicken\\\\f0b588b7-60010-1670807010.png', 'dataset\\\\images\\\\chicken\\\\06d11c9a-60010-1670840926.png', 'dataset\\\\images\\\\chicken\\\\a0852f21-60010-1670933720.png', 'dataset\\\\images\\\\chicken\\\\f3df0efb-60010-1671022771.png', 'dataset\\\\images\\\\chicken\\\\4dd5dbbc-60010-1670723204.png', 'dataset\\\\images\\\\chicken\\\\1a8f0fe8-60010-1670806996.png', 'dataset\\\\images\\\\chicken\\\\b7b85b8a-60010-1670840867_2.png', 'dataset\\\\images\\\\chicken\\\\bb433aea-60010-1671178319.png', 'dataset\\\\images\\\\chicken\\\\4b76b8cb-60010-1670840902.png', 'dataset\\\\images\\\\chicken\\\\cac827fd-60010-1671112242.png', 'dataset\\\\images\\\\chicken\\\\560b38ea-60010-1671614377.png', 'dataset\\\\images\\\\chicken\\\\bf37ddf8-60010-1670723693.png', 'dataset\\\\images\\\\chicken\\\\59d985ec-60010-1671022773.png', 'dataset\\\\images\\\\chicken\\\\69010411-60010-1671528024.png', 'dataset\\\\images\\\\chicken\\\\179d3549-60010-1671527852.png', 'dataset\\\\images\\\\chicken\\\\21cb3393-60010-1670840880.png', 'dataset\\\\images\\\\chicken\\\\cce77440-60010-1671614755.png', 'dataset\\\\images\\\\chicken\\\\0530188d-60010-1671527598.png', 'dataset\\\\images\\\\chicken\\\\88f9d28a-60010-1671615000.png', 'dataset\\\\images\\\\chicken\\\\fa58297f-60010-1671614702.png', 'dataset\\\\images\\\\chicken\\\\e1cc89c9-60010-1671022757.png', 'dataset\\\\images\\\\chicken\\\\08898be9-60010-1671693159.png', 'dataset\\\\images\\\\chicken\\\\eca570cb-60010-1671448496.png', 'dataset\\\\images\\\\chicken\\\\1da08dad-60010-1670840917.png', 'dataset\\\\images\\\\chicken\\\\e8f25b61-60010-1671178423.png', 'dataset\\\\images\\\\chicken\\\\6cf4239f-60010-1671448488.png', 'dataset\\\\images\\\\chicken\\\\ea5c68c6-60010-1670722970.png', 'dataset\\\\images\\\\chicken\\\\be7cb0be-60010-1670840889.png', 'dataset\\\\images\\\\chicken\\\\cf41ac62-60010-1671613961.png', 'dataset\\\\images\\\\chicken\\\\99316512-60010-1671022744.png', 'dataset\\\\images\\\\chicken\\\\c6e7b76b-60010-1670840890.png', 'dataset\\\\images\\\\chicken\\\\9dc71229-60010-1671528082.png', 'dataset\\\\images\\\\chicken\\\\b81b7ad3-60010-1670933742.png', 'dataset\\\\images\\\\chicken\\\\868d1471-60010-1671022781.png', 'dataset\\\\images\\\\chicken\\\\89aba38c-60010-1671614496.png', 'dataset\\\\images\\\\chicken\\\\7e9cbe53-60010-1671022729.png', 'dataset\\\\images\\\\chicken\\\\a5aee532-60010-1670840911_2.png', 'dataset\\\\images\\\\chicken\\\\acb46205-60010-1670840929.png', 'dataset\\\\images\\\\chicken\\\\90dbbfe3-60010-1671022747.png', 'dataset\\\\images\\\\chicken\\\\c50e7cec-60010-1671022755.png', 'dataset\\\\images\\\\chicken\\\\7d12d388-60010-1670840883.png', 'dataset\\\\images\\\\chicken\\\\60c4864d-60010-1671615932.png', 'dataset\\\\images\\\\chicken\\\\2381210f-60010-1671528455.png', 'dataset\\\\images\\\\chicken\\\\d3bc4100-60010-1671179475.png', 'dataset\\\\images\\\\chicken\\\\222dcd45-60010-1670933772.png', 'dataset\\\\images\\\\chicken\\\\1edad345-60010-1671448494_2.png', 'dataset\\\\images\\\\chicken\\\\c031bd10-60010-1671694982.png', 'dataset\\\\images\\\\chicken\\\\938c86d1-60010-1671615210.png', 'dataset\\\\images\\\\chicken\\\\7f811df1-60010-1671614609.png', 'dataset\\\\images\\\\chicken\\\\4598094e-60010-1671529195.png', 'dataset\\\\images\\\\chicken\\\\7c003b49-60010-1671529074.png', 'dataset\\\\images\\\\chicken\\\\b0afc66a-60010-1671527553.png', 'dataset\\\\images\\\\chicken\\\\241e7c62-60010-1671528005.png', 'dataset\\\\images\\\\chicken\\\\e1046873-60010-1670657126.png', 'dataset\\\\images\\\\chicken\\\\9e9ef478-60010-1670840898.png', 'dataset\\\\images\\\\chicken\\\\5da0a920-60010-1670806975.png', 'dataset\\\\images\\\\chicken\\\\9c990405-60010-1671526792.png', 'dataset\\\\images\\\\chicken\\\\ef4a5ae8-60010-1670643923.png', 'dataset\\\\images\\\\chicken\\\\20ec7ad3-60010-1671527229.png', 'dataset\\\\images\\\\chicken\\\\d77b512e-60010-1670806985.png', 'dataset\\\\images\\\\chicken\\\\33e6f1c2-60010-1671529227.png', 'dataset\\\\images\\\\chicken\\\\ec2c061c-60010-1671529096.png', 'dataset\\\\images\\\\chicken\\\\9cd53ceb-60010-1671615753.png', 'dataset\\\\images\\\\chicken\\\\9057b8ec-60010-1670657316.png', 'dataset\\\\images\\\\chicken\\\\a477f48b-60010-1671527755.png', 'dataset\\\\images\\\\chicken\\\\64b7532d-60010-1670840896.png', 'dataset\\\\images\\\\chicken\\\\b9503e96-60010-1671527952.png', 'dataset\\\\images\\\\chicken\\\\2ba2f980-60010-1671179202.png', 'dataset\\\\images\\\\chicken\\\\12cd088f-60010-1671527494.png', 'dataset\\\\images\\\\chicken\\\\44cff3f7-60010-1671614098.png', 'dataset\\\\images\\\\chicken\\\\4f1b51e3-60010-1670840870_2.png', 'dataset\\\\images\\\\chicken\\\\6174ced6-60010-1671022763.png', 'dataset\\\\images\\\\chicken\\\\22951283-60010-1671022768.png', 'dataset\\\\images\\\\chicken\\\\86d833aa-60010-1671529097.png', 'dataset\\\\images\\\\chicken\\\\09874e53-60010-1670840878.png', 'dataset\\\\images\\\\chicken\\\\8e62678e-60010-1670636525.png', 'dataset\\\\images\\\\chicken\\\\c20e69ff-60010-1671614474.png', 'dataset\\\\images\\\\chicken\\\\21350e93-60010-1671528674.png', 'dataset\\\\images\\\\chicken\\\\8a806c94-60010-1671527354.png', 'dataset\\\\images\\\\chicken\\\\2cfd3141-60010-1670657406.png', 'dataset\\\\images\\\\chicken\\\\360692ea-60010-1671527933.png', 'dataset\\\\images\\\\chicken\\\\30a7ada3-60010-1671022777.png', 'dataset\\\\images\\\\chicken\\\\d214bb6b-60010-1671448492.png', 'dataset\\\\images\\\\chicken\\\\1f29b3c3-60010-1670643934.png', 'dataset\\\\images\\\\chicken\\\\87d3675c-60010-1670643920.png', 'dataset\\\\images\\\\chicken\\\\632cc77a-60010-1670807013.png', 'dataset\\\\images\\\\chicken\\\\9acd83ea-60010-1670724834.png', 'dataset\\\\images\\\\chicken\\\\82652b74-60010-1670643915.png', 'dataset\\\\images\\\\chicken\\\\7bd47deb-60010-1671614152.png', 'dataset\\\\images\\\\chicken\\\\78195c41-60010-1670840888.png', 'dataset\\\\images\\\\chicken\\\\4f07ad86-60010-1671448484.png', 'dataset\\\\images\\\\chicken\\\\c805a4eb-60010-1671022749.png', 'dataset\\\\images\\\\chicken\\\\e154f6d0-60010-1670933715.png', 'dataset\\\\images\\\\chicken\\\\8c558680-60010-1671176972.png', 'dataset\\\\images\\\\chicken\\\\369502e4-60010-1671022762.png', 'dataset\\\\images\\\\chicken\\\\5b948ccf-60010-1671528369.png', 'dataset\\\\images\\\\chicken\\\\9f5ada9b-60010-1671448489.png', 'dataset\\\\images\\\\chicken\\\\40dac4eb-60010-1670724838.png', 'dataset\\\\images\\\\chicken\\\\b90ca0d7-60010-1670656439.png', 'dataset\\\\images\\\\chicken\\\\4ef8a848-60010-1671179474.png', 'dataset\\\\images\\\\chicken\\\\bad56ab2-60010-1670723495.png', 'dataset\\\\images\\\\chicken\\\\93ceae1e-60010-1671693248.png', 'dataset\\\\images\\\\chicken\\\\66f69688-60010-1671526699.png', 'dataset\\\\images\\\\chicken\\\\89944054-60010-1670656493.png', 'dataset\\\\images\\\\chicken\\\\20a8c8b0-60010-1670643901.png', 'dataset\\\\images\\\\chicken\\\\e8deed0c-60010-1670724857.png', 'dataset\\\\images\\\\chicken\\\\5fb908fa-60010-1670643928.png', 'dataset\\\\images\\\\chicken\\\\a47680df-60010-1671448486.png', 'dataset\\\\images\\\\chicken\\\\aa7e0df3-60010-1671022750.png', 'dataset\\\\images\\\\chicken\\\\9e5ceb12-60010-1670807000.png', 'dataset\\\\images\\\\chicken\\\\85117929-60010-1670840878_2.png', 'dataset\\\\images\\\\chicken\\\\d20836b4-60010-1670643939.png', 'dataset\\\\images\\\\chicken\\\\e25af754-60010-1670933764.png', 'dataset\\\\images\\\\chicken\\\\0cb77722-60010-1670933722.png', 'dataset\\\\images\\\\chicken\\\\d817fb94-60010-1670840906_2.png', 'dataset\\\\images\\\\chicken\\\\4b4e7b4c-60010-1671179227.png', 'dataset\\\\images\\\\chicken\\\\41c9ed8c-60010-1671178828.png', 'dataset\\\\images\\\\chicken\\\\65d4b8cc-maxresdefault.jpg', 'dataset\\\\images\\\\chicken\\\\e6e5ac7a-60010-1670840919.png', 'dataset\\\\images\\\\chicken\\\\8da17fea-60010-1670840866.png', 'dataset\\\\images\\\\chicken\\\\c5d8b79e-60010-1670806977.png', 'dataset\\\\images\\\\chicken\\\\e2442a89-60010-1671527551.png', 'dataset\\\\images\\\\chicken\\\\cd9579b9-60010-1671022772.png', 'dataset\\\\images\\\\chicken\\\\bc50b2a6-60010-1671179553.png', 'dataset\\\\images\\\\chicken\\\\a9f829d0-60010-1670722842.png', 'dataset\\\\images\\\\chicken\\\\6a782d4e-60010-1671527803.png', 'dataset\\\\images\\\\chicken\\\\f39c6da0-60010-1671022760.png', 'dataset\\\\images\\\\chicken\\\\6a9e731d-60010-1670569232.png', 'dataset\\\\images\\\\chicken\\\\64bf7d0e-60010-1671615418.png', 'dataset\\\\images\\\\chicken\\\\831a7367-60010-1671527728.png', 'dataset\\\\images\\\\chicken\\\\be118985-60010-1670656949.png', 'dataset\\\\images\\\\chicken\\\\bc7a8851-60010-1670840869.png', 'dataset\\\\images\\\\chicken\\\\95b11a04-60010-1670643922.png', 'dataset\\\\images\\\\chicken\\\\4b250c75-60010-1671448496_2.png', 'dataset\\\\images\\\\chicken\\\\4bb58733-60010-1671177272.png', 'dataset\\\\images\\\\chicken\\\\c1b1e7c3-60010-1671178797.png', 'dataset\\\\images\\\\chicken\\\\aaf890b9-60010-1671022737.png', 'dataset\\\\images\\\\chicken\\\\d1d9ca89-60010-1670657234.png', 'dataset\\\\images\\\\chicken\\\\c34eaef7-60010-1670933766.png', 'dataset\\\\images\\\\chicken\\\\d3d28c19-60010-1671527785.png', 'dataset\\\\images\\\\chicken\\\\f563dbd9-60010-1670933770.png', 'dataset\\\\images\\\\chicken\\\\f64b7cb5-60010-1670840897.png', 'dataset\\\\images\\\\chicken\\\\fc347aed-60010-1670643900.png', 'dataset\\\\images\\\\chicken\\\\a7685764-60010-1670933740.png', 'dataset\\\\images\\\\chicken\\\\23edad0c-60010-1671528475.png', 'dataset\\\\images\\\\chicken\\\\f90be513-60010-1671022758.png', 'dataset\\\\images\\\\chicken\\\\e2cadeb9-60010-1670840922.png', 'dataset\\\\images\\\\chicken\\\\a52a68e8-60010-1670806981.png', 'dataset\\\\images\\\\chicken\\\\e736f658-60010-1671695155.png', 'dataset\\\\images\\\\chicken\\\\49316b07-60010-1671614177.png', 'dataset\\\\images\\\\chicken\\\\3d6ebb59-60010-1671448480.png', 'dataset\\\\images\\\\chicken\\\\b05630f6-60010-1671694846.png', 'dataset\\\\images\\\\chicken\\\\4ee541ff-60010-1671448493.png', 'dataset\\\\images\\\\chicken\\\\c2b89ca1-60010-1670840899.png', 'dataset\\\\images\\\\chicken\\\\5ff91996-60010-1671527805.png', 'dataset\\\\images\\\\chicken\\\\b4f1de5b-60010-1671527751.png', 'dataset\\\\images\\\\chicken\\\\6f840a5f-60010-1671615474.png', 'dataset\\\\images\\\\chicken\\\\67d0622d-60010-1670807002.png', 'dataset\\\\images\\\\chicken\\\\5c188370-60010-1671179531.png', 'dataset\\\\images\\\\chicken\\\\90559958-60010-1671615305.png', 'dataset\\\\images\\\\chicken\\\\bbe13242-60010-1671448497.png', 'dataset\\\\images\\\\chicken\\\\f53f3f40-60010-1670656337.png', 'dataset\\\\images\\\\chicken\\\\d5b8f4ce-60010-1671179530.png', 'dataset\\\\images\\\\chicken\\\\fd16201b-60010-1671527621.png', 'dataset\\\\images\\\\chicken\\\\562a5731-60010-1670840906.png', 'dataset\\\\images\\\\chicken\\\\018caa0f-60010-1670643909.png', 'dataset\\\\images\\\\chicken\\\\92e45514-60010-1670933738.png', 'dataset\\\\images\\\\chicken\\\\f59c53f3-60010-1671179060.png', 'dataset\\\\images\\\\chicken\\\\74aae126-60010-1670806976.png', 'dataset\\\\images\\\\chicken\\\\55978acc-60010-1670840925_2.png', 'dataset\\\\images\\\\chicken\\\\56469b15-60010-1670807004.png', 'dataset\\\\images\\\\chicken\\\\67c61b65-60010-1671022756.png', 'dataset\\\\images\\\\chicken\\\\184004c8-60010-1671111899.png', 'dataset\\\\images\\\\chicken\\\\27eb84ff-60010-1671448486_2.png', 'dataset\\\\images\\\\chicken\\\\b171cf37-60010-1670933769.png', 'dataset\\\\images\\\\chicken\\\\deb7bab3-60010-1670933733.png', 'dataset\\\\images\\\\chicken\\\\4094227d-60010-1671614633.png', 'dataset\\\\images\\\\chicken\\\\b640cfe9-60010-1670723704.png', 'dataset\\\\images\\\\chicken\\\\eea6e684-60010-1671614680.png', 'dataset\\\\images\\\\chicken\\\\504cd0c4-60010-1670657432.png', 'dataset\\\\images\\\\chicken\\\\43282201-60010-1671022743.png', 'dataset\\\\images\\\\chicken\\\\582da56c-60010-1670657154.png', 'dataset\\\\images\\\\chicken\\\\f36910e1-60010-1671179027.png', 'dataset\\\\images\\\\chicken\\\\e22c5e5c-60010-1670933757.png', 'dataset\\\\images\\\\chicken\\\\53105dd3-60010-1670840876.png', 'dataset\\\\images\\\\chicken\\\\3be54a72-60010-1671179372.png', 'dataset\\\\images\\\\chicken\\\\f8753923-60010-1670723170.png', 'dataset\\\\images\\\\chicken\\\\ceb94f74-60010-1671528726.png', 'dataset\\\\images\\\\chicken\\\\6beafc27-60010-1670643908.png', 'dataset\\\\images\\\\chicken\\\\7a2e53b6-60010-1671616710.png', 'dataset\\\\images\\\\chicken\\\\740200ba-60010-1670656625.png', 'dataset\\\\images\\\\chicken\\\\346a23e7-60010-1670722868.png', 'dataset\\\\images\\\\chicken\\\\3ef85f4d-60010-1670840920.png', 'dataset\\\\images\\\\chicken\\\\d397aae3-60010-1671177473.png', 'dataset\\\\images\\\\chicken\\\\3339a811-60010-1670657515.png', 'dataset\\\\images\\\\chicken\\\\b3b4809f-60010-1671527619.png', 'dataset\\\\images\\\\chicken\\\\5effd554-60010-1670643921.png', 'dataset\\\\images\\\\chicken\\\\2ea30622-60010-1670840924.png', 'dataset\\\\images\\\\chicken\\\\03176b7f-60010-1670807011.png', 'dataset\\\\images\\\\chicken\\\\c91df240-60010-1670807005.png', 'dataset\\\\images\\\\chicken\\\\9af236fe-60010-1670724856.png', 'dataset\\\\images\\\\chicken\\\\d35531ac-60010-1670643927.png', 'dataset\\\\images\\\\chicken\\\\5a3f8e07-60010-1670840882.png', 'dataset\\\\images\\\\chicken\\\\b711bb4a-60010-1671614545.png', 'dataset\\\\images\\\\chicken\\\\c8a3ffe7-60010-1670806989.png', 'dataset\\\\images\\\\chicken\\\\b987cac4-60010-1670840903.png', 'dataset\\\\images\\\\chicken\\\\d1a361b8-60010-1671528547.png', 'dataset\\\\images\\\\chicken\\\\7e031c50-60010-1670840917_2.png', 'dataset\\\\images\\\\chicken\\\\aae503a6-60010-1671695275.png', 'dataset\\\\images\\\\chicken\\\\0afe8f04-60010-1670656521.png', 'dataset\\\\images\\\\chicken\\\\c0f1aebb-60010-1670656782.png', 'dataset\\\\images\\\\chicken\\\\e35f0df8-60010-1670656648.png', 'dataset\\\\images\\\\chicken\\\\471f1824-60010-1670933718.png', 'dataset\\\\images\\\\chicken\\\\4245e279-60010-1671527254.png', 'dataset\\\\images\\\\chicken\\\\8af240f5-60010-1670840912.png', 'dataset\\\\images\\\\chicken\\\\c8435c0f-60010-1670840872.png', 'dataset\\\\images\\\\chicken\\\\3204f10f-60010-1671022721.png', 'dataset\\\\images\\\\chicken\\\\c2b494e2-60010-1671178625.png', 'dataset\\\\images\\\\chicken\\\\89944054-60010-1670656493.png', 'dataset\\\\images\\\\chicken\\\\9e3e4165-60010-1670656029.png', 'dataset\\\\images\\\\chicken\\\\f86d4666-60010-1671615024.png', 'dataset\\\\images\\\\chicken\\\\fa3112cb-60010-1670656981.png', 'dataset\\\\images\\\\chicken\\\\0ea4fac5-60010-1671022746.png', 'dataset\\\\images\\\\chicken\\\\33e3bdee-60010-1670933771.png', 'dataset\\\\images\\\\chicken\\\\1b173b90-60010-1671694954.png', 'dataset\\\\images\\\\chicken\\\\42bc7b74-60010-1670724859.png', 'dataset\\\\images\\\\chicken\\\\d72bde11-60010-1671179401.png', 'dataset\\\\images\\\\chicken\\\\33c13354-60010-1671527207.png', 'dataset\\\\images\\\\chicken\\\\28e99a56-60010-1670724848.png', 'dataset\\\\images\\\\chicken\\\\cd629468-60010-1671179422.png', 'dataset\\\\images\\\\chicken\\\\45b70878-60010-1671448500_2.png', 'dataset\\\\images\\\\chicken\\\\001c5000-60010-1670840900.png', 'dataset\\\\images\\\\chicken\\\\161514ce-60010-1671177053.png', 'dataset\\\\images\\\\chicken\\\\f4fe0d32-60010-1670933756.png', 'dataset\\\\images\\\\chicken\\\\04b651f1-60010-1670643897.png', 'dataset\\\\images\\\\chicken\\\\78a375a6-60010-1670722925.png', 'dataset\\\\images\\\\chicken\\\\3e4b4312-60010-1671022748.png', 'dataset\\\\images\\\\chicken\\\\5eb38524-60010-1671526834.png', 'dataset\\\\images\\\\chicken\\\\ae6850a0-60010-1671615230.png', 'dataset\\\\images\\\\chicken\\\\07c7bd4d-60010-1671527313.png', 'dataset\\\\images\\\\chicken\\\\141337b3-60010-1670840873.png', 'dataset\\\\images\\\\chicken\\\\3659bcc8-60010-1671527331.png', 'dataset\\\\images\\\\chicken\\\\4362ed4e-60010-1670933751.png', 'dataset\\\\images\\\\chicken\\\\6bdc8e1d-60010-1671448502_2.png', 'dataset\\\\images\\\\chicken\\\\a018342b-60010-1670933760.png', 'dataset\\\\images\\\\chicken\\\\8db1c763-60010-1671614450.png', 'dataset\\\\images\\\\chicken\\\\47a5dfa3-60010-1671177165.png', 'dataset\\\\images\\\\chicken\\\\84db4136-60010-1671022731.png', 'dataset\\\\images\\\\chicken\\\\2d534571-60010-1670933726.png', 'dataset\\\\images\\\\chicken\\\\4f76aa32-60010-1670840889_2.png', 'dataset\\\\images\\\\chicken\\\\8ff75c77-60010-1671615877.png', 'dataset\\\\images\\\\chicken\\\\43b4a616-60010-1670840905.png', 'dataset\\\\images\\\\chicken\\\\4f447855-60010-1670840875.png', 'dataset\\\\images\\\\chicken\\\\717a972d-60010-1671613738.png', 'dataset\\\\images\\\\chicken\\\\02e4529c-60010-1670933732.png', 'dataset\\\\images\\\\chicken\\\\f23a7d19-60010-1671615108.png', 'dataset\\\\images\\\\chicken\\\\f39e8540-60010-1671528635.png', 'dataset\\\\images\\\\chicken\\\\26a6bc8e-60010-1670657380.png', 'dataset\\\\images\\\\chicken\\\\6c72ad27-60010-1671022767.png', 'dataset\\\\images\\\\chicken\\\\30dea54f-60010-1671527909.png', 'dataset\\\\images\\\\chicken\\\\2856f0bd-60010-1670840895.png', 'dataset\\\\images\\\\chicken\\\\e87dcbd0-60010-1671615133.png', 'dataset\\\\images\\\\chicken\\\\472737bd-60010-1671179400.png', 'dataset\\\\images\\\\chicken\\\\3250161a-60010-1670656466.png', 'dataset\\\\images\\\\chicken\\\\8a57e824-60010-1671529218.png', 'dataset\\\\images\\\\chicken\\\\d203ead9-60010-1670656750.png', 'dataset\\\\images\\\\chicken\\\\857bf430-60010-1670643936.png', 'dataset\\\\images\\\\chicken\\\\fdabd496-60010-1671022722.png', 'dataset\\\\images\\\\chicken\\\\1a9e9a76-60010-1670723094.png', 'dataset\\\\images\\\\chicken\\\\8b60dd8f-60010-1671528185.png', 'dataset\\\\images\\\\chicken\\\\5e912480-60010-1670657487.png', 'dataset\\\\images\\\\chicken\\\\7a90342b-60010-1670840904_2.png', 'dataset\\\\images\\\\chicken\\\\14bc6aff-60010-1671528564.png', 'dataset\\\\images\\\\chicken\\\\b2ef6db5-60010-1670643911.png', 'dataset\\\\images\\\\chicken\\\\7e57f89d-60010-1670840916.png', 'dataset\\\\images\\\\chicken\\\\5475166f-broiler-chickens-shed-focus-single-immobile-leg-animal-welfare-stretch_iIFmwTs.jpg', 'dataset\\\\images\\\\chicken\\\\582da56c-60010-1670657154.png', 'dataset\\\\images\\\\chicken\\\\78ee312f-60010-1670933755.png', 'dataset\\\\images\\\\chicken\\\\772fdc00-60010-1670840877.png', 'dataset\\\\images\\\\chicken\\\\6e20290e-60010-1670933765.png', 'dataset\\\\images\\\\chicken\\\\7fdfb1bc-60010-1671528987.png', 'dataset\\\\images\\\\chicken\\\\861a4040-60010-1670933758.png', 'dataset\\\\images\\\\chicken\\\\c1684c0a-60010-1671022726.png', 'dataset\\\\images\\\\chicken\\\\d3ff807c-60010-1671448502.png', 'dataset\\\\images\\\\chicken\\\\a52a68e8-60010-1670806981.png', 'dataset\\\\images\\\\chicken\\\\94b171a6-60010-1670643918.png', 'dataset\\\\images\\\\chicken\\\\220446ec-60010-1671528609.png', 'dataset\\\\images\\\\chicken\\\\ec1e3aa1-60010-1671616661.png', 'dataset\\\\images\\\\chicken\\\\5050268b-60010-1671177326.png', 'dataset\\\\images\\\\chicken\\\\f69cfb98-IMG_Broilers_0001.jpg', 'dataset\\\\images\\\\chicken\\\\695297f2-60010-1671179322.png', 'dataset\\\\images\\\\chicken\\\\476199d2-60010-1671528436.png', 'dataset\\\\images\\\\chicken\\\\bacd904f-60010-1671022742.png', 'dataset\\\\images\\\\chicken\\\\10804881-60010-1670840891.png', 'dataset\\\\images\\\\chicken\\\\f7900aaa-60010-1671614022.png', 'dataset\\\\images\\\\chicken\\\\49e8d47e-60010-1671614729.png', 'dataset\\\\images\\\\chicken\\\\f3e1e65e-60010-1670933750.png', 'dataset\\\\images\\\\chicken\\\\4bfd41db-60010-1671022734.png', 'dataset\\\\images\\\\chicken\\\\f8b23ae3-60010-1670657075.png', 'dataset\\\\images\\\\chicken\\\\be118985-60010-1670656949.png', 'dataset\\\\images\\\\chicken\\\\45bbe454-60010-1671528545.png', 'dataset\\\\images\\\\chicken\\\\a05a1ba7-60010-1670933761.png', 'dataset\\\\images\\\\chicken\\\\54218b5c-60010-1671615445.png', 'dataset\\\\images\\\\chicken\\\\047f39c3-60010-1670806994.png', 'dataset\\\\images\\\\chicken\\\\fc388051-60010-1670643919.png', 'dataset\\\\images\\\\chicken\\\\08651065-60010-1671022738.png', 'dataset\\\\images\\\\chicken\\\\60069990-60010-1671615360.png', 'dataset\\\\images\\\\chicken\\\\c3b62e8d-60010-1671614973.png', 'dataset\\\\images\\\\chicken\\\\0ef9816a-60010-1671177142.png', 'dataset\\\\images\\\\chicken\\\\2c1978d9-60010-1671178649.png', 'dataset\\\\images\\\\chicken\\\\4ba392fa-60010-1670933763.png', 'dataset\\\\images\\\\chicken\\\\9a6c4f28-60010-1670656045.png', 'dataset\\\\images\\\\chicken\\\\74fd1966-60010-1671526974.png', 'dataset\\\\images\\\\chicken\\\\85255343-60010-1670840928.png', 'dataset\\\\images\\\\chicken\\\\05ed12b3-60010-1671022728.png', 'dataset\\\\images\\\\chicken\\\\e64a338f-60010-1670723142.png', 'dataset\\\\images\\\\chicken\\\\5d310ea9-60010-1670807012.png', 'dataset\\\\images\\\\chicken\\\\cfa082c9-60010-1671022769.png', 'dataset\\\\images\\\\chicken\\\\22836d17-60010-1670656725.png', 'dataset\\\\images\\\\chicken\\\\28dc648c-60010-1670636469.png', 'dataset\\\\images\\\\chicken\\\\525b5a5d-60010-1671178795.png', 'dataset\\\\images\\\\chicken\\\\a829d367-60010-1670724833.png', 'dataset\\\\images\\\\chicken\\\\71930b9f-60010-1670933714_2.png', 'dataset\\\\images\\\\chicken\\\\fab68f8c-untitled-1-139.jpeg', 'dataset\\\\images\\\\chicken\\\\e7c41781-60010-1670656394.png', 'dataset\\\\images\\\\chicken\\\\a7844622-60010-1671693222.png', 'dataset\\\\images\\\\chicken\\\\013cffe7-60010-1671528587.png', 'dataset\\\\images\\\\chicken\\\\14dca22a-60010-1671694789.png', 'dataset\\\\images\\\\chicken\\\\4eb83c28-60010-1671176492.png', 'dataset\\\\images\\\\chicken\\\\056c2afb-60010-1671613908.png', 'dataset\\\\images\\\\chicken\\\\928c29a6-60010-1670933736.png', 'dataset\\\\images\\\\chicken\\\\d1529bc9-60010-1670657206.png', 'dataset\\\\images\\\\chicken\\\\c5beabfe-60010-1670933767.png', 'dataset\\\\images\\\\chicken\\\\0141d03f-60010-1671614656.png', 'dataset\\\\images\\\\chicken\\\\01de5b61-60010-1670656602.png', 'dataset\\\\images\\\\chicken\\\\db67ce80-60010-1671448482_2.png', 'dataset\\\\images\\\\chicken\\\\1a083d73-60010-1670724831.png', 'dataset\\\\images\\\\chicken\\\\b44fbda1-60010-1670643932.png', 'dataset\\\\images\\\\chicken\\\\01de5b61-60010-1670656602.png', 'dataset\\\\images\\\\chicken\\\\fbc09abe-60010-1670807009.png', 'dataset\\\\images\\\\chicken\\\\629e10fc-60010-1671527974.png', 'dataset\\\\images\\\\chicken\\\\18a03a59-60010-1671527827.png']\n"
     ]
    }
   ],
   "source": [
    "directory = \"C:/Users/ASUS/Documents/LatihanData/dead_chicken/images\"\n",
    "output_file = \"C:/Users/ASUS/Documents/LatihanData/list_dead.txt\"\n",
    "print(imagePaths)\n",
    "# Memeriksa apakah direktori ada\n",
    "if os.path.exists(directory):\n",
    "    # Memeriksa apakah direktori adalah sebuah direktori\n",
    "    if os.path.isdir(directory):\n",
    "        # Mendapatkan daftar file dalam direktori\n",
    "        files = os.listdir(directory)\n",
    "        \n",
    "        # Memfilter hanya file dengan ekstensi gambar\n",
    "        image_files = [file for file in files if file.endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "        \n",
    "        # Menuliskan nama semua file gambar ke dalam file txt\n",
    "        with open(output_file, 'w') as f:\n",
    "            for image_file in image_files:\n",
    "                image_dead = os.path.join('dead_chicken\\images', image_file)\n",
    "                f.write(image_dead + '\\n')\n",
    "                \n",
    "    else:\n",
    "        print(\"Path bukan direktori.\")\n",
    "else:\n",
    "    print(\"Path tidak ditemukan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading object detector...\n"
     ]
    }
   ],
   "source": [
    "# determine the input file type, but assume that we're working with\n",
    "# single input image\n",
    "# filetype = mimetypes.guess_type(args[\"input\"])[0]\n",
    "predictImage = open(\"list_dead.txt\").read().strip().split(\"\\n\")\n",
    "# if the file type is a text file, then we need to process *multiple*\n",
    "# images\n",
    "# if \"text/plain\" == filetype:\n",
    "# \t# load the image paths in our testing file\n",
    "# \timagePaths = open(args[\"input\"]).read().strip().split(\"\\n\")\n",
    "\t\n",
    "# load our object detector, set it evaluation mode, and label\n",
    "# encoder from disk\n",
    "print(\"[INFO] loading object detector...\")\n",
    "model = torch.load(MODEL_PATH).to(DEVICE)\n",
    "model.eval()\n",
    "le = pickle.loads(open(LE_PATH, \"rb\").read())\n",
    "# define normalization transforms\n",
    "transforms = Transforms.Compose([\n",
    "\tTransforms.ToPILImage(),\n",
    "\tTransforms.ToTensor(),\n",
    "\tTransforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "\n",
    "# loop over the images that we'll be testing using our bounding box\n",
    "# regression model\n",
    "for imagePath in predictImage:\n",
    "\t# load the image, copy it, swap its colors channels, resize it, and\n",
    "\t# bring its channel dimension forward\n",
    "\timage = cv2.imread(imagePath)\n",
    "\torig = image.copy()\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\timage = image.transpose((2, 0, 1))\n",
    "\t# convert image to PyTorch tensor, normalize it, flash it to the\n",
    "\t# current device, and add a batch dimension\n",
    "\timage = torch.from_numpy(image)\n",
    "\timage = transforms(image).to(DEVICE)\n",
    "\timage = image.unsqueeze(0)\n",
    "\t# predict the bounding box of the object along with the class\n",
    "\t# label\n",
    "\t(boxPreds, labelPreds) = model(image)\n",
    "\t(startX, startY, endX, endY) = boxPreds[0]\n",
    "\t(startX2, startY2, endX2, endY2) = boxPreds[0]\n",
    "\t# determine the class label with the largest predicted\n",
    "\t# probability\n",
    "\tlabelPreds = torch.nn.Softmax(dim=-1)(labelPreds)\n",
    "\ti = labelPreds.argmax(dim=-1).cpu()\n",
    "\tlabel = le.inverse_transform(i)[0]\n",
    "\t# resize the original image such that it fits on our screen, and\n",
    "\t# grab its dimensions\n",
    "\t(h2, w2) = orig.shape[:2]\n",
    "\t# scale the predicted bounding box coordinates based on the image\n",
    "\t# dimensions\n",
    "\tstartX2 = int(startX2 * w2)\n",
    "\tstartY2 = int(startY2 * h2)\n",
    "\tendX2 = int(endX2 * w2)\n",
    "\tendY2 = int(endY2 * h2)\n",
    "\tcrop_path = os.path.join('crop_dead', os.path.basename(imagePath))\n",
    "\tcrop_image = orig[int(startY2):int(endY2), int(startX2):int(endX2)]\n",
    "\tcv2.imwrite(crop_path, crop_image)\n",
    "\torig = imutils.resize(orig, width=300)\n",
    "\t(h, w) = orig.shape[:2]\n",
    "\t# scale the predicted bounding box coordinates based on the image\n",
    "\t# dimensions\n",
    "\tstartX = int(startX * w)\n",
    "\tstartY = int(startY * h)\n",
    "\tendX = int(endX * w)\n",
    "\tendY = int(endY * h)\n",
    "\t# draw the predicted bounding box and class label on the image\n",
    "\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\tcv2.putText(orig, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t0.65, (0, 255, 0), 2)\n",
    "\tcv2.rectangle(orig, (startX, startY), (endX, endY),\n",
    "\t\t(0, 255, 0), 2)\n",
    "\t# show the output image\n",
    "\t# cv2.imshow(\"Output\", orig)\n",
    "\t# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # partition the data into training and testing splits using 80% of\n",
    "# # the data for training and the remaining 20% for testing\n",
    "# split = train_test_split(data, labels, bboxes, imagePaths,\n",
    "# \ttest_size=0.20, random_state=42)\n",
    "# # unpack the data split\n",
    "# (trainImages, testImages) = split[:2]\n",
    "# (trainLabels, testLabels) = split[2:4]\n",
    "# (trainBBoxes, testBBoxes) = split[4:6]\n",
    "# (trainPaths, testPaths) = split[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert NumPy arrays to PyTorch tensors\n",
    "# (trainImages, testImages) = torch.tensor(trainImages),\\\n",
    "# \ttorch.tensor(testImages)\n",
    "# (trainLabels, testLabels) = torch.tensor(trainLabels),\\\n",
    "# \ttorch.tensor(testLabels)\n",
    "# (trainBBoxes, testBBoxes) = torch.tensor(trainBBoxes),\\\n",
    "# \ttorch.tensor(testBBoxes)\n",
    "# # define normalization transforms\n",
    "# transforms = transforms.Compose([\n",
    "# \ttransforms.ToPILImage(),\n",
    "# \ttransforms.ToTensor(),\n",
    "# \ttransforms.Normalize(mean=MEAN, std=STD)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert NumPy arrays to PyTorch datasets\n",
    "# trainDS = CustomTensorDataset((trainImages, trainLabels, trainBBoxes),\n",
    "# \ttransforms=transforms)\n",
    "# testDS = CustomTensorDataset((testImages, testLabels, testBBoxes),\n",
    "# \ttransforms=transforms)\n",
    "# print(\"[INFO] total training samples: {}...\".format(len(trainDS)))\n",
    "# print(\"[INFO] total test samples: {}...\".format(len(testDS)))\n",
    "# # calculate steps per epoch for training and validation set\n",
    "# trainSteps = len(trainDS) // BATCH_SIZE\n",
    "# valSteps = len(testDS) // BATCH_SIZE\n",
    "# # create data loaders\n",
    "# trainLoader = DataLoader(trainDS, batch_size= BATCH_SIZE,\n",
    "# \tshuffle=True, pin_memory= PIN_MEMORY)\n",
    "# testLoader = DataLoader(testDS, batch_size= BATCH_SIZE, pin_memory= PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write the testing image paths to disk so that we can use then\n",
    "# # when evaluating/testing our object detector\n",
    "# print(\"[INFO] saving testing image paths...\")\n",
    "# f = open(TEST_PATHS, \"w\")\n",
    "# f.write(\"\\n\".join(testPaths))\n",
    "# f.close()\n",
    "# # load the ResNet50 network\n",
    "# resnet = resnet50(pretrained=True)\n",
    "# # freeze all ResNet50 layers so they will *not* be updated during the\n",
    "# # training process\n",
    "# for param in resnet.parameters():\n",
    "# \tparam.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create our custom object detector model and flash it to the current\n",
    "# # device\n",
    "# objectDetector = ObjectDetector(resnet, len(le.classes_))\n",
    "# objectDetector = objectDetector.to(DEVICE)\n",
    "# # define our loss functions\n",
    "# classLossFunc = CrossEntropyLoss()\n",
    "# bboxLossFunc = MSELoss()\n",
    "# # initialize the optimizer, compile the model, and show the model\n",
    "# # summary\n",
    "# opt = Adam(objectDetector.parameters(), lr=INIT_LR)\n",
    "# print(objectDetector)\n",
    "# # initialize a dictionary to store training history\n",
    "# H = {\"total_train_loss\": [], \"total_val_loss\": [], \"train_class_acc\": [],\n",
    "# \t \"val_class_acc\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loop over epochs\n",
    "# print(\"[INFO] training the network...\")\n",
    "# startTime = time.time()\n",
    "# for e in tqdm(range(NUM_EPOCHS)):\n",
    "# \t# set the model in training mode\n",
    "# \tobjectDetector.train()\n",
    "# \t# initialize the total training and validation loss\n",
    "# \ttotalTrainLoss = 0\n",
    "# \ttotalValLoss = 0\n",
    "# \t# initialize the number of correct predictions in the training\n",
    "# \t# and validation step\n",
    "# \ttrainCorrect = 0\n",
    "# \tvalCorrect = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \t# loop over the training set\n",
    "# for (images, labels, bboxes) in trainLoader:\n",
    "# \t\t# send the input to the device\n",
    "# \t\t(images, labels, bboxes) = (images.to(DEVICE),\n",
    "# \t\t\tlabels.to(DEVICE), bboxes.to(DEVICE))\n",
    "# \t\t# perform a forward pass and calculate the training loss\n",
    "# \t\tpredictions = objectDetector(images)\n",
    "# \t\tbboxLoss = bboxLossFunc(predictions[0], bboxes)\n",
    "# \t\tclassLoss = classLossFunc(predictions[1], labels)\n",
    "# \t\ttotalLoss = (BBOX * bboxLoss) + (LABELS * classLoss)\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "# \t\t# zero out the gradients, perform the backpropagation step,\n",
    "# \t\t# and update the weights\n",
    "# \t\topt.zero_grad()\n",
    "# \t\ttotalLoss.backward()\n",
    "# \t\topt.step()\n",
    "# \t\t# add the loss to the total training loss so far and\n",
    "# \t\t# calculate the number of correct predictions\n",
    "# \t\ttotalTrainLoss += totalLoss\n",
    "# \t\ttrainCorrect += (predictions[1].argmax(1) == labels).type(\n",
    "# \t\t\ttorch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loop over the training set\n",
    "# for batch_idx, (images, labels, bboxes) in enumerate(trainLoader):\n",
    "#     # send the input to the device\n",
    "#     (images, labels, bboxes) = (images.to(DEVICE), labels.to(DEVICE), bboxes.to(DEVICE))\n",
    "\n",
    "#     # perform a forward pass and calculate the training loss\n",
    "#     predictions = objectDetector(images)\n",
    "#     bboxLoss = bboxLossFunc(predictions[0], bboxes)\n",
    "#     classLoss = classLossFunc(predictions[1], labels)\n",
    "#     totalLoss = (BBOX * bboxLoss) + (LABELS * classLoss)\n",
    "\n",
    "#     # visualize the images\n",
    "#     if batch_idx % 10 == 0:  # Adjust the frequency of visualization as needed\n",
    "#         # Convert tensors to NumPy arrays for visualization\n",
    "#         images_np = images.cpu().numpy()\n",
    "#         bboxes_np = bboxes.cpu().numpy()\n",
    "\n",
    "#         # Plot the images with bounding boxes\n",
    "#         for i in range(images_np.shape[0]):\n",
    "#             image = np.transpose(images_np[i], (1, 2, 0))\n",
    "#             # image = (image * 255).astype(np.uint8)\n",
    "#             plt.imshow(image)\n",
    "            \n",
    "#             # Assuming bboxes are in (x, y, w, h) format\n",
    "#             bbox = bboxes_np[i]\n",
    "#             print(bbox[0],bbox[1],bbox[2]-bbox[0], bbox[3]-bbox[1])\n",
    "#             # plt.gca().add_patch(plt.Rectangle((bbox[0], bbox[1]), bbox[2]-bbox[0], bbox[3]-bbox[1], fill=False))\n",
    "\n",
    "#             # plt.title(f'Batch {batch_idx}, Image {i}')\n",
    "#             # plt.show()\n",
    "\n",
    "#     # rest of your training loop code...\n",
    "\n",
    "#     # zero out the gradients, perform the backpropagation step,\n",
    "#     # and update the weights\n",
    "#     opt.zero_grad()\n",
    "#     totalLoss.backward()\n",
    "#     opt.step()\n",
    "\n",
    "#     # add the loss to the total training loss so far and\n",
    "#     # calculate the number of correct predictions\n",
    "#     totalTrainLoss += totalLoss\n",
    "#     trainCorrect += (predictions[1].argmax(1) == labels).type(torch.float).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \t# switch off autograd\n",
    "# with torch.no_grad():\n",
    "# \t\t# set the model in evaluation mode\n",
    "# \t\tobjectDetector.eval()\n",
    "# \t\t# loop over the validation set\n",
    "# \t\tfor (images, labels, bboxes) in testLoader:\n",
    "# \t\t\t# send the input to the device\n",
    "# \t\t\t(images, labels, bboxes) = (images.to(DEVICE),\n",
    "# \t\t\t\tlabels.to(DEVICE), bboxes.to(DEVICE))\n",
    "# \t\t\t# make the predictions and calculate the validation loss\n",
    "# \t\t\tpredictions = objectDetector(images)\n",
    "# \t\t\tbboxLoss = bboxLossFunc(predictions[0], bboxes)\n",
    "# \t\t\tclassLoss = classLossFunc(predictions[1], labels)\n",
    "# \t\t\ttotalLoss = (BBOX * bboxLoss) + \\\n",
    "# \t\t\t\t(LABELS * classLoss)\n",
    "# \t\t\ttotalValLoss += totalLoss\n",
    "# \t\t\t# calculate the number of correct predictions\n",
    "# \t\t\tvalCorrect += (predictions[1].argmax(1) == labels).type(\n",
    "# \t\t\t\ttorch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \t# calculate the average training and validation loss\n",
    "# avgTrainLoss = totalTrainLoss / trainSteps\n",
    "# avgValLoss = totalValLoss / valSteps\n",
    "# \t# calculate the training and validation accuracy\n",
    "# trainCorrect = trainCorrect / len(trainDS)\n",
    "# valCorrect = valCorrect / len(testDS)\n",
    "# \t# update our training history\n",
    "# H[\"total_train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "# H[\"train_class_acc\"].append(trainCorrect)\n",
    "# H[\"total_val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "# H[\"val_class_acc\"].append(valCorrect)\n",
    "# \t# print the model training and validation information\n",
    "# print(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
    "# print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
    "# \tavgTrainLoss, trainCorrect))\n",
    "# print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\".format(\n",
    "# \tavgValLoss, valCorrect))\n",
    "# endTime = time.time()\n",
    "# print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "# \tendTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # serialize the model to disk\n",
    "# print(\"[INFO] saving object detector model...\")\n",
    "# torch.save(objectDetector, MODEL_PATH)\n",
    "# # serialize the label encoder to disk\n",
    "# print(\"[INFO] saving label encoder...\")\n",
    "# f = open(LE_PATH, \"wb\")\n",
    "# f.write(pickle.dumps(le))\n",
    "# f.close()\n",
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure()\n",
    "# plt.plot(H[\"total_train_loss\"], label=\"total_train_loss\")\n",
    "# plt.plot(H[\"total_val_loss\"], label=\"total_val_loss\")\n",
    "# plt.plot(H[\"train_class_acc\"], label=\"train_class_acc\")\n",
    "# plt.plot(H[\"val_class_acc\"], label=\"val_class_acc\")\n",
    "# plt.title(\"Total Training Loss and Classification Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# # save the training plot\n",
    "# plotPath = os.path.sep.join([PLOTS_PATH, \"training.png\"])\n",
    "# plt.savefig(plotPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
